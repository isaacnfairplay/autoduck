# Task: For the task, I'll create a concise example demonstrating DuckDB's array_transform function for numeric list manipulation:

```python
import duckdb

con = duckdb.connect()

# Transform numeric array by adding 10 to each element
rel = con.query('''
SELECT array_transform([1, 2, 3, 4], x -> x + 10) as incremented_array
''')

print(rel.execute().fetchall())
```

This targeted implementation demonstrates DuckDB's array_transform capability by incrementing list elements, highlighting its flexible functional SQL querying approach.

## Step 1: For the task, I'll create a concise example demonstrating DuckDB's array_transform function for numeric list manipulation:

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create and transform numeric array using array_transform
result = conn.execute('''
    SELECT array_transform([1, 2, 3, 4, 5], x -> x * 2) as doubled_array
''').fetchall()

print(result[0][0])  # Output: [2, 4, 6, 8, 10]
```

**Result**: [([2, 4, 6, 8, 10],)]

**Explanation**: Demonstrates DuckDB's array_transform function, which applies a lambda function to each element of an array, multiplying each numeric value by 2.
## Step 2: ```python

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create table with decimal precision and perform precise financial calculation
conn.execute('''CREATE TABLE investments (
    asset_name VARCHAR,
    investment_amount DECIMAL(10,2),
    growth_rate DECIMAL(5,4)
)''')

conn.execute('''INSERT INTO investments VALUES
    ('Stock A', 1000.00, 0.0725),
    ('Bond B', 5000.00, 0.0345),
    ('Real Estate', 10000.00, 0.0512)''')

# Calculate precise investment growth with high decimal precision
result = conn.execute('''SELECT 
    asset_name, 
    investment_amount, 
    ROUND(investment_amount * (1 + growth_rate), 2) as projected_value
FROM investments
ORDER BY projected_value DESC''').fetchall()

for row in result:
    print(f"{row[0]}: ${row[1]} -> ${row[2]}")
```

**Result**: [('Real Estate', Decimal('10000.00'), Decimal('10512.00')), ('Bond B', Decimal('5000.00'), Decimal('5172.50')), ('Stock A', Decimal('1000.00'), Decimal('1072.50'))]

**Explanation**: Demonstrates DuckDB's robust handling of decimal precision in financial calculations, showing complex table creation, insertion, and precise numeric transformations with DECIMAL types and floating-point arithmetic.
## Step 3: import duckdb

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create time series data with window function
conn.execute('''CREATE TABLE stock_prices (
    symbol VARCHAR,
    trade_date DATE,
    closing_price DECIMAL(10,2)
)''')

conn.execute('''INSERT INTO stock_prices VALUES
    ('AAPL', '2023-01-01', 145.50),
    ('AAPL', '2023-01-02', 146.75),
    ('AAPL', '2023-01-03', 144.25),
    ('GOOG', '2023-01-01', 90.10),
    ('GOOG', '2023-01-02', 91.45),
    ('GOOG', '2023-01-03', 89.90)''')

# Calculate rolling 2-day moving average for each stock
result = conn.execute('''SELECT 
    symbol, 
    trade_date, 
    closing_price,
    AVG(closing_price) OVER (
        PARTITION BY symbol 
        ORDER BY trade_date 
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    ) as moving_avg
FROM stock_prices
ORDER BY symbol, trade_date''').fetchall()

for row in result:
    print(f'{row[0]} on {row[1]}: Price={row[2]}, Moving Avg={row[3]}')
```

**Result**: [('AAPL', datetime.date(2023, 1, 1), Decimal('145.50'), 145.5), ('AAPL', datetime.date(2023, 1, 2), Decimal('146.75'), 146.125), ('AAPL', datetime.date(2023, 1, 3), Decimal('144.25'), 145.5), ('GOOG', datetime.date(2023, 1, 1), Decimal('90.10'), 90.1), ('GOOG', datetime.date(2023, 1, 2), Decimal('91.45'), 90.775), ('GOOG', datetime.date(2023, 1, 3), Decimal('89.90'), 90.675)]

**Explanation**: Demonstrates DuckDB window function for calculating a 2-day moving average across time series stock price data, partitioned by stock symbol and ordered chronologically
## Step 4: con = duckdb.connect()

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create a geographic data table with point coordinates
conn.execute('''CREATE TABLE locations (
    city VARCHAR,
    latitude DOUBLE,
    longitude DOUBLE
)''')

conn.execute('''INSERT INTO locations VALUES
    ('New York', 40.7128, -74.0060),
    ('London', 51.5074, -0.1278),
    ('Tokyo', 35.6762, 139.6503)
''')

# Calculate great circle distance between points using haversine formula
result = conn.execute('''SELECT 
    city, 
    ROUND(6371 * 2 * ASIN(SQRT(
        POWER(SIN((latitude - 40.7128) * PI() / 360), 2) +
        COS(latitude * PI() / 180) * COS(40.7128 * PI() / 180) *
        POWER(SIN((longitude - (-74.0060)) * PI() / 360), 2)
    )), 2) as distance_km
FROM locations
WHERE city != 'New York'
ORDER BY distance_km''').fetchall()

for row in result:
    print(f'{row[0]}: {row[1]} km from New York')
```

**Result**: [('London', 5570.22), ('Tokyo', 10851.73)]

**Explanation**: Demonstrates geospatial distance calculation using trigonometric SQL functions, showing DuckDB's ability to perform complex geographical computations with standard SQL syntax
## Step 5: # Transform numeric array by adding 10 to each element

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

result = conn.execute('''
    SELECT array_transform([1, 2, 3, 4, 5], x -> x + 10) as transformed_array
''').fetchall()

print(result[0][0])  # Output: [11, 12, 13, 14, 15]
```

**Result**: [([11, 12, 13, 14, 15],)]

**Explanation**: Demonstrates DuckDB's array_transform function by adding 10 to each element in a numeric array, showcasing functional transformation of array elements with lambda-like syntax
## Step 6: rel = con.query('''

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create a graph-like adjacency table of employees and their managers
conn.execute('''CREATE TABLE employee_hierarchy (
    employee_id INTEGER,
    name VARCHAR,
    manager_id INTEGER
)''')

conn.execute('''INSERT INTO employee_hierarchy VALUES
    (1, 'Alice', NULL),
    (2, 'Bob', 1),
    (3, 'Charlie', 1),
    (4, 'David', 2),
    (5, 'Eve', 3)''')

# Use recursive common table expression to trace reporting paths
result = conn.execute('''WITH RECURSIVE reporting_chain AS (
    SELECT employee_id, name, manager_id, name as path
    FROM employee_hierarchy WHERE manager_id IS NULL
    UNION ALL
    SELECT e.employee_id, e.name, e.manager_id, 
           rc.path || ' -> ' || e.name
    FROM employee_hierarchy e
    JOIN reporting_chain rc ON e.manager_id = rc.employee_id
)
SELECT * FROM reporting_chain ORDER BY path''').fetchall()

for row in result:
    print(f'Employee Path: {row[2]}')
```

**Result**: [(1, 'Alice', None, 'Alice'), (2, 'Bob', 1, 'Alice -> Bob'), (4, 'David', 2, 'Alice -> Bob -> David'), (3, 'Charlie', 1, 'Alice -> Charlie'), (5, 'Eve', 3, 'Alice -> Charlie -> Eve')]

**Explanation**: Demonstrates a recursive CTE to explore hierarchical employee reporting structures by tracing management paths from root managers down to individual contributors
## Step 7: SELECT array_transform([1, 2, 3, 4], x -> x + 10) as incremented_array

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')
result = conn.execute('SELECT array_transform([1, 2, 3, 4], x -> x + 10) as incremented_array').fetchall()
print(result[0][0])
```

**Result**: [([11, 12, 13, 14],)]

**Explanation**: Uses DuckDB's array_transform function to increment each array element by 10, demonstrating lambda-style inline transformation of array elements
## Step 8: ''')

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create a product inventory with categories and perform conditional aggregation
conn.execute('''CREATE TABLE product_inventory (
    product_id INTEGER,
    category VARCHAR,
    stock_quantity INTEGER,
    unit_price DECIMAL(10,2)
)''')

conn.execute('''INSERT INTO product_inventory VALUES
    (1, 'Electronics', 50, 299.99),
    (2, 'Clothing', 100, 49.50),
    (3, 'Electronics', 25, 599.99),
    (4, 'Home', 75, 129.99),
    (5, 'Clothing', 60, 79.99)''')

# Compute total value and average price per category, with stock threshold filter
result = conn.execute('''SELECT 
    category, 
    SUM(stock_quantity * unit_price) as total_category_value,
    AVG(unit_price) as avg_price
FROM product_inventory
WHERE stock_quantity > 30
GROUP BY category
ORDER BY total_category_value DESC''').fetchall()

for row in result:
    print(f'Category: {row[0]}, Total Value: ${row[1]}, Avg Price: ${row[2]:.2f}')
```

**Result**: [('Electronics', Decimal('14999.50'), 299.99), ('Clothing', Decimal('9749.40'), 64.745), ('Home', Decimal('9749.25'), 129.99)]

**Explanation**: Demonstrates DuckDB's aggregation capabilities by analyzing product inventory across categories, computing total inventory value and average price while filtering for products with sufficient stock.
## Step 9: print(rel.execute().fetchall())

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create a sample table
conn.execute('CREATE TABLE numbers (value INTEGER)')
conn.execute('INSERT INTO numbers VALUES (1), (2), (3), (4), (5)')

# Create a relation and execute
rel = conn.table('numbers').filter('value > 2')
print(rel.execute().fetchall())
```

**Result**: [('Electronics', Decimal('14999.50'), 299.99), ('Clothing', Decimal('9749.40'), 64.745), ('Home', Decimal('9749.25'), 129.99)]

**Explanation**: Demonstrates creating a table, generating a relational algebra expression with filter, and executing the relation to fetch results.
## Step 10: ```

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create multi-range temporal histogram for event frequency
conn.execute('''CREATE TABLE event_log (
    event_time TIMESTAMP,
    event_type VARCHAR
)''')

conn.execute('''INSERT INTO event_log VALUES
    ('2023-01-01 10:15:00', 'login'),
    ('2023-01-01 10:20:00', 'purchase'),
    ('2023-01-01 11:05:00', 'logout'),
    ('2023-01-02 09:30:00', 'login'),
    ('2023-01-02 14:45:00', 'purchase')''')

# Compute hourly event frequency with time-based windowing
result = conn.execute('''SELECT 
    DATE_TRUNC('hour', event_time) as hour_bucket,
    COUNT(*) as event_count,
    LIST(event_type) as event_types
FROM event_log
GROUP BY hour_bucket
ORDER BY hour_bucket''').fetchall()

for row in result:
    print(f'Hour: {row[0]}, Events: {row[1]}, Types: {row[2]})')
```

**Result**: [(datetime.datetime(2023, 1, 1, 10, 0), 2, ['login', 'purchase']), (datetime.datetime(2023, 1, 1, 11, 0), 1, ['logout']), (datetime.datetime(2023, 1, 2, 9, 0), 1, ['login']), (datetime.datetime(2023, 1, 2, 14, 0), 1, ['purchase'])]

**Explanation**: Demonstrates advanced temporal event analysis using time-based bucketing, event counting, and type aggregation in a single DuckDB query
## Step 11: This targeted implementation demonstrates DuckDB's array_transform capability by incrementing list elements, highlighting its flexible functional SQL querying approach.

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')
result = conn.execute('SELECT array_transform([1, 2, 3, 4, 5], x -> x * 3) as tripled_array').fetchall()
print(result[0][0])
```

**Result**: [([3, 6, 9, 12, 15],)]

**Explanation**: Demonstrates DuckDB's array_transform function by multiplying each list element by 3, showcasing inline lambda-style transformations in SQL queries
