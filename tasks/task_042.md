# Task: Here's a concise example demonstrating DuckDB's array_transform function with a targeted numeric list transformation:

```python
import duckdb

con = duckdb.connect()

# Transform numeric array by applying POWER function
rel = con.query('''
SELECT array_transform([2, 3, 4, 5], x -> x * x) as squared_array
''')

print(rel.execute().fetchall())
```

This targeted implementation showcases DuckDB's array transformation capability by squaring each element, highlighting its flexible functional SQL querying approach.

## Step 1: Here's a concise example demonstrating DuckDB's array_transform function with a targeted numeric list transformation:

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Transform array by doubling each numeric value
result = conn.execute("""
    SELECT array_transform([1, 2, 3, 4, 5], x -> x * 2) AS doubled_array
""").fetchone()[0]

print(result)  # Expected: [2, 4, 6, 8, 10]
```

**Result**: [2, 4, 6, 8, 10]

**Explanation**: Demonstrates DuckDB's array_transform function to perform element-wise numeric transformation using a lambda expression, efficiently mapping each array element through a simple computation.
## Step 2: ```python

**Generated by**: Anthropic

```python
import duckdb

# Complex nested array transformation and filtering
conn = duckdb.connect(':memory:')

result = conn.execute("""
    SELECT 
        array_filter(
            array_transform(
                [[1, 2], [3, 4], [5, 6]], 
                x -> [x[0] * 2, x[1] * 3]
            ), 
            x -> x[0] > 5
        ) AS transformed_arrays
""").fetchone()[0]

print(result)  # Expected: [[6, 9], [10, 18]]
```

**Result**: []

**Explanation**: Demonstrates chained array manipulation using array_transform and array_filter, showing nested array transformations where each inner array is modified and then filtered based on a condition
## Step 3: import duckdb

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create a temporary table of products
conn.execute("CREATE TABLE products (id INTEGER, name VARCHAR, price DECIMAL(10,2))")
conn.execute("INSERT INTO products VALUES (1, 'Apple', 0.50), (2, 'Banana', 0.75), (3, 'Orange', 0.60)")

# Use window function to calculate running total of prices
result = conn.execute("SELECT name, price, SUM(price) OVER (ORDER BY price) as running_total FROM products").fetchall()

for row in result:
    print(f"{row[0]}: Price ${row[1]}, Running Total ${row[2]})")
```

**Result**: [('Apple', Decimal('0.50'), Decimal('0.50')), ('Orange', Decimal('0.60'), Decimal('1.10')), ('Banana', Decimal('0.75'), Decimal('1.85'))]

**Explanation**: Demonstrates a window function (SUM... OVER) to calculate a running total of product prices, showing DuckDB's analytical SQL capabilities
## Step 4: con = duckdb.connect()

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create sample table with geographic data
conn.execute("CREATE TABLE cities (name VARCHAR, country VARCHAR, population INTEGER)")
conn.execute("INSERT INTO cities VALUES ('Paris', 'France', 2161000), ('London', 'UK', 8982000), ('Berlin', 'Germany', 3669000)")

# Use window function to rank cities by population within their country
result = conn.execute("""
    SELECT 
        name, 
        country, 
        population, 
        RANK() OVER (PARTITION BY country ORDER BY population DESC) as population_rank
    FROM cities
""").fetchall()

for row in result:
    print(f"{row[0]} ({row[1]}): Population {row[2]}, Rank {row[3]}")
```

**Result**: [('Paris', 'France', 2161000, 1), ('Berlin', 'Germany', 3669000, 1), ('London', 'UK', 8982000, 1)]

**Explanation**: Demonstrates window function with partitioning, showing how to rank cities by population within their respective countries using RANK() OVER clause
## Step 5: # Transform numeric array by applying POWER function

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

result = conn.execute("""
    SELECT array_transform([1, 2, 3, 4, 5], x -> POWER(x, 2)) AS squared_array
""").fetchone()[0]

print(result)  # Expected: [1, 4, 9, 16, 25]
```

**Result**: [1.0, 4.0, 9.0, 16.0, 25.0]

**Explanation**: Demonstrates array transformation by applying the POWER function to square each numeric element using DuckDB's array_transform and SQL lambda expression.
## Step 6: rel = con.query('''

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Compute rolling average of sales with window function
conn.execute('CREATE TABLE sales (date DATE, amount DECIMAL(10,2))')
conn.execute("INSERT INTO sales VALUES ('2023-01-01', 100.50), ('2023-01-02', 200.75), ('2023-01-03', 150.25)")

result = conn.execute("""
    SELECT 
        date, 
        amount, 
        AVG(amount) OVER (ORDER BY date ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) as rolling_avg
    FROM sales
""").fetchall()

for row in result:
    print(f"Date: {row[0]}, Amount: ${row[1]}, Rolling Avg: ${row[2]:.2f}")
```

**Result**: [(datetime.date(2023, 1, 1), Decimal('100.50'), 100.5), (datetime.date(2023, 1, 2), Decimal('200.75'), 150.625), (datetime.date(2023, 1, 3), Decimal('150.25'), 175.5)]

**Explanation**: Demonstrates a window function calculating a moving/rolling average over a time series sales dataset, showing how to compute cumulative metrics dynamically in DuckDB
## Step 7: SELECT array_transform([2, 3, 4, 5], x -> x * x) as squared_array

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

result = conn.execute("""
    SELECT array_transform([2, 3, 4, 5], x -> x * x) as squared_array
""").fetchone()[0]

print(result)  # Expected: [4, 9, 16, 25]
```

**Result**: [4, 9, 16, 25]

**Explanation**: Demonstrates array transformation using array_transform() to square each element, applying a lambda-like function directly in the SQL query.
## Step 8: ''')

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create a table with complex nested data
conn.execute('CREATE TABLE nested_data (id INTEGER, details STRUCT(name VARCHAR, scores INT[]))')
conn.execute("INSERT INTO nested_data VALUES (1, {'name': 'Alice', 'scores': [85, 90, 95]})")

# Extract and transform nested data using SQL
result = conn.execute("""
    SELECT 
        id, 
        details.name, 
        array_transform(details.scores, x -> x + 5) as boosted_scores
    FROM nested_data
""").fetchall()

for row in result:
    print(f"ID: {row[0]}, Name: {row[1]}, Boosted Scores: {row[2]})")
```

**Result**: [(1, 'Alice', [90, 95, 100])]

**Explanation**: Demonstrates DuckDB's advanced nested data handling by creating a table with a structured column containing an array, then using array_transform() to modify nested scores dynamically.
## Step 9: print(rel.execute().fetchall())

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')
conn.execute('CREATE TABLE numbers (value INTEGER)')
conn.execute('INSERT INTO numbers VALUES (1), (2), (3), (4), (5)')

rel = conn.table('numbers').filter('value > 2').project('value * 2 AS doubled_value')
print(rel.execute().fetchall())
```

**Result**: [(1, 'Alice', [90, 95, 100])]

**Explanation**: Creates an in-memory table of numbers, filters for values greater than 2, projects and doubles those values using DuckDB's relational API method chaining
## Step 10: ```

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create a table with sensor readings and calculate moving range
conn.execute('CREATE TABLE sensor_data (timestamp TIMESTAMP, temperature DECIMAL(5,2))')
conn.execute("INSERT INTO sensor_data VALUES ('2024-01-01 10:00:00', 22.5), ('2024-01-01 10:15:00', 23.1), ('2024-01-01 10:30:00', 21.9), ('2024-01-01 10:45:00', 22.7)")

result = conn.execute("""
SELECT 
    timestamp, 
    temperature, 
    ABS(temperature - LAG(temperature) OVER (ORDER BY timestamp)) AS temperature_change
FROM sensor_data
""").fetchall()

for row in result:
    print(f"Timestamp: {row[0]}, Temperature: {row[1]}°C, Change: {row[2]}°C")
```

**Result**: [(datetime.datetime(2024, 1, 1, 10, 0), Decimal('22.50'), None), (datetime.datetime(2024, 1, 1, 10, 15), Decimal('23.10'), Decimal('0.60')), (datetime.datetime(2024, 1, 1, 10, 30), Decimal('21.90'), Decimal('1.20')), (datetime.datetime(2024, 1, 1, 10, 45), Decimal('22.70'), Decimal('0.80'))]

**Explanation**: Demonstrates window functions in DuckDB by calculating temperature change between consecutive sensor readings using LAG() and ABS() functions
## Step 11: This targeted implementation showcases DuckDB's array transformation capability by squaring each element, highlighting its flexible functional SQL querying approach.

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

result = conn.execute("""
    SELECT array_transform([1, 2, 3, 4, 5], x -> x * x) as squared_array
""").fetchone()[0]

print(result)  # Expected: [1, 4, 9, 16, 25]
```

**Result**: [1, 4, 9, 16, 25]

**Explanation**: Demonstrates DuckDB's array_transform function to square each numeric element in an array using a lambda-like functional SQL transformation, showcasing the API's flexible numeric manipulation capabilities.
