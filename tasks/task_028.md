# Task: I'll generate a concise example demonstrating DuckDB's lateral join capability to explore complex data relationships:

```python
import duckdb

con = duckdb.connect()

# Create base and related tables
con.execute('''
CREATE TABLE departments(dept_id INTEGER, dept_name VARCHAR);
CREATE TABLE employees(emp_id INTEGER, name VARCHAR, dept_id INTEGER);

INSERT INTO departments VALUES (1, 'Sales'), (2, 'Engineering');
INSERT INTO employees VALUES (101, 'Alice', 1), (102, 'Bob', 2);
'''
)

# Use LATERAL JOIN to correlate results dynamically
rel = con.query('''
SELECT 
    d.dept_name, 
    e.name,
    (SELECT COUNT(*) FROM employees sub WHERE sub.dept_id = d.dept_id) as dept_headcount
FROM departments d,
LATERAL (SELECT name FROM employees WHERE dept_id = d.dept_id) e
''')

print(rel.execute().fetchall())
```

This example showcases DuckDB's LATERAL JOIN for dynamic, correlated subquery resolution.

## Step 1: I'll generate a concise example demonstrating DuckDB's lateral join capability to explore complex data relationships:

Failed after 3 attempts: Binder Error: Referenced column "Sales" not found in FROM clause!

LINE 1: INSERT INTO departments VALUES (1, "Sales"), (2, "Engineering")
                                           ^
## Step 2: ```python

**Generated by**: Anthropic

```python
import duckdb

# Create an in-memory database and sample data
conn = duckdb.connect(':memory:')
conn.execute('CREATE TABLE orders (order_id INT, customer_id INT, total_amount DECIMAL(10,2))')
conn.executemany('INSERT INTO orders VALUES (?, ?, ?)', [(1, 101, 150.50), (2, 102, 275.75), (3, 101, 89.99)])

# Demonstrate window function to rank orders per customer
result = conn.execute('''
    SELECT 
        order_id, 
        customer_id, 
        total_amount,
        RANK() OVER (PARTITION BY customer_id ORDER BY total_amount DESC) as order_rank
    FROM orders
''').fetchall()

print(result)
```

**Result**: [(2, 102, Decimal('275.75'), 1), (1, 101, Decimal('150.50'), 1), (3, 101, Decimal('89.99'), 2)]

**Explanation**: Demonstrates a window function (RANK()) partitioned by customer_id, showing how to rank orders within each customer's purchase history by total amount.
## Step 3: import duckdb

**Generated by**: Anthropic

```python
import duckdb

# Create in-memory database
conn = duckdb.connect(':memory:')

# Create table with product sales data
conn.execute('CREATE TABLE product_sales (product_id INT, category TEXT, sales DECIMAL(10,2))')
conn.executemany('INSERT INTO product_sales VALUES (?, ?, ?)', [
    (1, 'Electronics', 1500.50),
    (2, 'Clothing', 850.25),
    (3, 'Electronics', 2200.75),
    (4, 'Books', 350.00)
])

# Use window function to calculate category-wise running total
result = conn.execute('''
    SELECT 
        product_id, 
        category, 
        sales, 
        SUM(sales) OVER (PARTITION BY category ORDER BY sales) as running_category_total
    FROM product_sales
''').fetchall()

print(result)
```

**Result**: [(1, 'Electronics', Decimal('1500.50'), Decimal('1500.50')), (3, 'Electronics', Decimal('2200.75'), Decimal('3701.25')), (4, 'Books', Decimal('350.00'), Decimal('350.00')), (2, 'Clothing', Decimal('850.25'), Decimal('850.25'))]

**Explanation**: Demonstrates a window function calculating running total within product categories, showcasing DuckDB's advanced analytical querying capabilities
## Step 4: con = duckdb.connect()

**Generated by**: Anthropic

```python
import duckdb

# Create an in-memory database
conn = duckdb.connect(':memory:')

# Create a table with employee performance data
conn.execute('CREATE TABLE employees (id INT, department TEXT, salary DECIMAL(10,2), performance_score FLOAT)')
conn.executemany('INSERT INTO employees VALUES (?, ?, ?, ?)', [
    (1, 'Sales', 55000.00, 4.5),
    (2, 'Marketing', 62000.00, 4.2),
    (3, 'Sales', 58000.00, 4.7),
    (4, 'Marketing', 59000.00, 3.9)
])

# Use window functions to calculate percentile rank within departments
result = conn.execute('''
    SELECT 
        id, 
        department, 
        salary, 
        performance_score,
        PERCENT_RANK() OVER (PARTITION BY department ORDER BY performance_score) as perf_percentile,
        NTILE(4) OVER (PARTITION BY department ORDER BY salary) as salary_quartile
    FROM employees
''').fetchall()

print(result)
```

**Result**: [(1, 'Sales', Decimal('55000.00'), 4.5, 0.0, 1), (3, 'Sales', Decimal('58000.00'), 4.699999809265137, 1.0, 2), (4, 'Marketing', Decimal('59000.00'), 3.9000000953674316, 0.0, 1), (2, 'Marketing', Decimal('62000.00'), 4.199999809265137, 1.0, 2)]

**Explanation**: Demonstrates advanced window functions PERCENT_RANK() and NTILE() to analyze employee performance and salary distribution within departments using DuckDB's analytical capabilities.
## Step 5: # Create base and related tables

**Generated by**: Anthropic

```python
import duckdb

# Create an in-memory database
conn = duckdb.connect(':memory:')

# Create authors table
conn.execute('CREATE TABLE authors (author_id INT PRIMARY KEY, name TEXT, country TEXT)')
conn.executemany('INSERT INTO authors VALUES (?, ?, ?)', [
    (1, 'Haruki Murakami', 'Japan'),
    (2, 'Chimamanda Ngozi Adichie', 'Nigeria'),
    (3, 'Kazuo Ishiguro', 'United Kingdom')
])

# Create books table with foreign key relationship
conn.execute('CREATE TABLE books (book_id INT PRIMARY KEY, title TEXT, author_id INT, publication_year INT, FOREIGN KEY(author_id) REFERENCES authors(author_id))')
conn.executemany('INSERT INTO books VALUES (?, ?, ?, ?)', [
    (101, 'Kafka on the Shore', 1, 2002),
    (102, 'Norwegian Wood', 1, 1987),
    (103, 'Americanah', 2, 2013),
    (104, 'Never Let Me Go', 3, 2005)
])

# Demonstrate join and filtering
result = conn.execute('''
    SELECT a.name, b.title, b.publication_year
    FROM authors a JOIN books b ON a.author_id = b.author_id
    WHERE a.country = 'Japan' AND b.publication_year > 1990
''').fetchall()

print(result)
```

**Result**: [('Haruki Murakami', 'Kafka on the Shore', 2002)]

**Explanation**: Creates authors and books tables with a foreign key relationship, demonstrating table creation, data insertion, and a complex join with filtering conditions across related tables.
## Step 6: con.execute('''

**Generated by**: Anthropic

```python
import duckdb

# Create in-memory database
conn = duckdb.connect(':memory:')

# Create time series data table
conn.execute('CREATE TABLE stock_prices (date DATE, symbol TEXT, price DECIMAL(10,2))')
conn.executemany('INSERT INTO stock_prices VALUES (?, ?, ?)', [
    ('2023-01-01', 'AAPL', 150.25),
    ('2023-01-02', 'AAPL', 152.50),
    ('2023-01-03', 'AAPL', 149.75),
    ('2023-01-01', 'GOOGL', 100.00),
    ('2023-01-02', 'GOOGL', 102.50)
])

# Use window function to calculate daily price change
result = conn.execute('''
    SELECT 
        symbol, 
        date, 
        price, 
        price - LAG(price) OVER (PARTITION BY symbol ORDER BY date) as price_change
    FROM stock_prices
''').fetchall()

print(result)
```

**Result**: [('GOOGL', datetime.date(2023, 1, 1), Decimal('100.00'), None), ('GOOGL', datetime.date(2023, 1, 2), Decimal('102.50'), Decimal('2.50')), ('AAPL', datetime.date(2023, 1, 1), Decimal('150.25'), None), ('AAPL', datetime.date(2023, 1, 2), Decimal('152.50'), Decimal('2.25')), ('AAPL', datetime.date(2023, 1, 3), Decimal('149.75'), Decimal('-2.75'))]

**Explanation**: Demonstrates time series analysis using DuckDB's window function LAG() to calculate daily price changes for stock symbols, partitioned by symbol and ordered chronologically.
## Step 7: CREATE TABLE departments(dept_id INTEGER, dept_name VARCHAR)

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')
conn.execute('CREATE TABLE departments(dept_id INTEGER, dept_name VARCHAR)')
conn.executemany('INSERT INTO departments VALUES (?, ?)', [
    (1, 'Sales'),
    (2, 'Marketing'),
    (3, 'Engineering')
])

result = conn.execute('SELECT * FROM departments').fetchall()
print(result)
```

**Result**: [(1, 'Sales'), (2, 'Marketing'), (3, 'Engineering')]

**Explanation**: Creates an in-memory departments table using DuckDB, demonstrates table creation, inserting sample data, and basic table query with fetchall()
## Step 8: CREATE TABLE employees(emp_id INTEGER, name VARCHAR, dept_id INTEGER)

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')
conn.execute('CREATE TABLE employees(emp_id INTEGER, name VARCHAR, dept_id INTEGER)')
conn.executemany('INSERT INTO employees VALUES (?, ?, ?)', [
    (1, 'Alice', 1),
    (2, 'Bob', 2),
    (3, 'Charlie', 1),
    (4, 'David', 3)
])

result = conn.execute('SELECT * FROM employees').fetchall()
print(result)
```

**Result**: [(1, 'Alice', 1), (2, 'Bob', 2), (3, 'Charlie', 1), (4, 'David', 3)]

**Explanation**: Creates an in-memory DuckDB database with employees table, inserts sample data, and demonstrates basic table creation and data insertion using executemany() method
## Step 9: INSERT INTO departments VALUES (1, 'Sales'), (2, 'Engineering')

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')
conn.execute('CREATE TABLE departments(dept_id INTEGER, dept_name VARCHAR)')
conn.executemany('INSERT INTO departments VALUES (?, ?)', [(1, 'Sales'), (2, 'Engineering')])
```

**Result**: [(1, 'Alice', 1), (2, 'Bob', 2), (3, 'Charlie', 1), (4, 'David', 3)]

**Explanation**: Creates an in-memory DuckDB database, defines a 'departments' table, and inserts two rows using executemany() with parameterized values.
## Step 10: INSERT INTO employees VALUES (101, 'Alice', 1), (102, 'Bob', 2)

Failed after 3 attempts: Catalog Error: Table with name employees does not exist!
Did you mean "pg_tables"?
## Step 11: '''

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('CREATE TABLE departments(dept_id INTEGER, dept_name VARCHAR)')
conn.executemany('INSERT INTO departments VALUES (?, ?)', [(1, 'Sales'), (2, 'Engineering')])

result = conn.execute('SELECT dept_name FROM departments WHERE dept_id > 0').fetchall()
print(result)
```

**Result**: [('Sales',), ('Engineering',)]

**Explanation**: Demonstrates creating an in-memory database table and performing a basic filtering query on departments based on department ID.
## Step 12: )

**Generated by**: Anthropic

```python
import duckdb

# Create in-memory database
conn = duckdb.connect(':memory:')

# Create users and purchases tables
conn.execute('CREATE TABLE users (user_id INT, name TEXT, country TEXT)')
conn.execute('CREATE TABLE purchases (purchase_id INT, user_id INT, amount DECIMAL(10,2))')

# Insert sample data
conn.executemany('INSERT INTO users VALUES (?, ?, ?)', [
    (1, 'Alice', 'USA'),
    (2, 'Bob', 'Canada'),
    (3, 'Charlie', 'UK')
])
conn.executemany('INSERT INTO purchases VALUES (?, ?, ?)', [
    (101, 1, 250.50),
    (102, 1, 100.25),
    (103, 2, 175.00)
])

# Demonstrate grouping and aggregation with join
result = conn.execute('''
    SELECT u.name, u.country, SUM(p.amount) as total_purchases
    FROM users u JOIN purchases p ON u.user_id = p.user_id
    GROUP BY u.name, u.country
    HAVING total_purchases > 200
''').fetchall()

print(result)
```

**Result**: [('Alice', 'USA', Decimal('350.75'))]

**Explanation**: Demonstrates a multi-table join with grouping, aggregation, and HAVING clause to find users with total purchases over $200, showcasing DuckDB's relational query capabilities
## Step 13: # Use LATERAL JOIN to correlate results dynamically

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create tables for products and discounts
conn.execute('CREATE TABLE products(product_id INT, name TEXT, price DECIMAL(10,2))')
conn.execute('CREATE TABLE discount_rules(min_price DECIMAL(10,2), discount_percentage DECIMAL(5,2))')

conn.executemany('INSERT INTO products VALUES (?, ?, ?)', [
    (1, 'Laptop', 1000.00),
    (2, 'Smartphone', 600.00),
    (3, 'Tablet', 400.00)
])

conn.executemany('INSERT INTO discount_rules VALUES (?, ?)', [
    (500.00, 10.0),
    (1000.00, 15.0)
])

# Use LATERAL JOIN to dynamically apply discounts
result = conn.execute('''
    SELECT 
        p.product_id, 
        p.name, 
        p.price, 
        d.discount_percentage,
        p.price * (1 - d.discount_percentage/100) as discounted_price
    FROM products p, LATERAL (
        SELECT discount_percentage 
        FROM discount_rules 
        WHERE p.price >= min_price 
        ORDER BY discount_percentage DESC 
        LIMIT 1
    ) d
''').fetchall()

print(result)
```

**Result**: [(2, 'Smartphone', Decimal('600.00'), Decimal('10.00'), 540.0), (1, 'Laptop', Decimal('1000.00'), Decimal('15.00'), 850.0)]

**Explanation**: This example demonstrates a LATERAL JOIN, which allows correlating results dynamically. Here, each product is matched with the most applicable discount rule based on its price, showing how LATERAL JOINs can perform row-by-row subqueries with correlated calculations.
## Step 14: rel = con.query('''

**Generated by**: Anthropic

```python
import duckdb

# Create recursive CTE to generate Fibonacci sequence
conn = duckdb.connect(':memory:')

result = conn.execute('''
WITH RECURSIVE fibonacci(n, a, b) AS (
    SELECT 0, 0, 1
    UNION ALL
    SELECT n+1, b, a+b
    FROM fibonacci
    WHERE n < 10
)
SELECT n, a as fibonacci_number
FROM fibonacci
''').fetchall()

print(result)
```

**Result**: [(0, 0), (1, 1), (2, 1), (3, 2), (4, 3), (5, 5), (6, 8), (7, 13), (8, 21), (9, 34), (10, 55)]

**Explanation**: Demonstrates a recursive common table expression (CTE) to generate the first 10 Fibonacci numbers using DuckDB's advanced SQL capabilities, showing how complex sequences can be computed efficiently within a single query.
## Step 15: SELECT

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')
conn.execute('CREATE TABLE users (id INT, name TEXT, age INT)')
conn.executemany('INSERT INTO users VALUES (?, ?, ?)', [(1, 'Alice', 30), (2, 'Bob', 25), (3, 'Charlie', 35)])

result = conn.execute('SELECT name, age FROM users WHERE age > 28').fetchall()
print(result)
```

**Result**: [('Alice', 30), ('Charlie', 35)]

**Explanation**: Demonstrates a basic SELECT query with a WHERE clause to filter rows based on an age condition. Creates an in-memory table and retrieves specific columns for users older than 28.
## Step 16: d.dept_name,

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('CREATE TABLE departments(dept_id INTEGER, dept_name VARCHAR)')
conn.executemany('INSERT INTO departments VALUES (?, ?)', [(1, 'Sales'), (2, 'Engineering')])

result = conn.execute('SELECT dept_name FROM departments WHERE dept_id > 0').fetchall()
print(result)
```

**Result**: [('Sales',), ('Engineering',)]

**Explanation**: Demonstrates creating an in-memory DuckDB table, inserting data, and performing a simple SELECT query with a filtering condition using the WHERE clause.
## Step 17: e.name,

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create organizations and employees tables
conn.execute('CREATE TABLE organizations(org_id INT, name TEXT)')
conn.execute('CREATE TABLE employees(emp_id INT, org_id INT, first_name TEXT, last_name TEXT, salary DECIMAL(10,2))')

# Insert sample data
conn.executemany('INSERT INTO organizations VALUES (?, ?)', [(1, 'TechCorp'), (2, 'DataInc')])
conn.executemany('INSERT INTO employees VALUES (?, ?, ?, ?, ?)', [
    (101, 1, 'Alice', 'Smith', 75000.00),
    (102, 1, 'Bob', 'Jones', 82000.00),
    (103, 2, 'Charlie', 'Brown', 68000.00)
])

# Complex join with aggregation and nested conditions
result = conn.execute('''
    SELECT 
        o.name as organization, 
        AVG(e.salary) as avg_salary,
        COUNT(*) as employee_count
    FROM organizations o
    JOIN employees e ON o.org_id = e.org_id
    WHERE e.salary > (
        SELECT AVG(salary) FROM employees
    )
    GROUP BY o.name
    HAVING COUNT(*) > 1
''').fetchall()

print(result)
```

**Result**: []

**Explanation**: Demonstrates a complex DuckDB query involving multi-table join, subquery, aggregation, and filtering, showcasing nested SQL capabilities with Python integration
## Step 18: (SELECT COUNT(*) FROM employees sub WHERE sub.dept_id = d.dept_id) as dept_headcount

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create departments and employees tables
conn.execute('CREATE TABLE departments(dept_id INTEGER, dept_name VARCHAR)')
conn.execute('CREATE TABLE employees(emp_id INTEGER, dept_id INTEGER, name VARCHAR)')

# Insert sample data
conn.executemany('INSERT INTO departments VALUES (?, ?)', [(1, 'Sales'), (2, 'Engineering'), (3, 'Marketing')])
conn.executemany('INSERT INTO employees VALUES (?, ?, ?)', [(1, 1, 'Alice'), (2, 1, 'Bob'), (3, 2, 'Charlie'), (4, 2, 'David'), (5, 3, 'Eve')])

# Use correlated subquery to count employees per department
result = conn.execute('''SELECT dept_name, (SELECT COUNT(*) FROM employees sub WHERE sub.dept_id = d.dept_id) as dept_headcount FROM departments d''').fetchall()

print(result)
```

**Result**: [('Sales', 2), ('Engineering', 2), ('Marketing', 1)]

**Explanation**: Demonstrates a correlated subquery that counts employees for each department by matching department IDs, illustrating a subquery that references the outer query's table.
## Step 19: FROM departments d,

Failed after 3 attempts: Catalog Error: Table with name employees does not exist!
Did you mean "pg_tables"?

LINE 5:     (SELECT COUNT(*) FROM employees e WHERE e.dept_id = d.dept_id) as employee_count
                                  ^
## Step 20: LATERAL (SELECT name FROM employees WHERE dept_id = d.dept_id) e

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create departments and employees tables
conn.execute('CREATE TABLE departments(dept_id INTEGER, dept_name VARCHAR)')
conn.execute('CREATE TABLE employees(emp_id INTEGER, dept_id INTEGER, name VARCHAR)')

# Insert sample data
conn.executemany('INSERT INTO departments VALUES (?, ?)', [(1, 'Sales'), (2, 'Engineering'), (3, 'Marketing')])
conn.executemany('INSERT INTO employees VALUES (?, ?, ?)', [(1, 1, 'Alice'), (2, 1, 'Bob'), (3, 2, 'Charlie'), (4, 2, 'David'), (5, 3, 'Eve')])

# Use LATERAL join to get employees per department dynamically
result = conn.execute('''
SELECT 
    d.dept_name, 
    e.name as employee_name
FROM 
    departments d,
    LATERAL (SELECT name FROM employees WHERE dept_id = d.dept_id) e
''').fetchall()

print(result)
```

**Result**: [('Sales', 'Bob'), ('Engineering', 'David'), ('Marketing', 'Eve'), ('Sales', 'Alice'), ('Engineering', 'Charlie')]

**Explanation**: Demonstrates DuckDB's LATERAL join to dynamically select employee names per department by correlated subquery, allowing flexible row-wise data retrieval across related tables.
## Step 21: ''')

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create a geospatial data simulation
conn.execute('CREATE TABLE locations (id INT, name TEXT, latitude FLOAT, longitude FLOAT)')
conn.executemany('INSERT INTO locations VALUES (?, ?, ?, ?)', [
    (1, 'New York', 40.7128, -74.0060),
    (2, 'London', 51.5074, -0.1278),
    (3, 'Tokyo', 35.6762, 139.6503)
])

# Calculate distance between two points using Haversine formula
result = conn.execute('''
    SELECT 
        name, 
        2 * 6371 * ASIN(
            SQRT(
                POWER(SIN((radians(35.6762) - radians(latitude)) / 2), 2) +
                COS(radians(latitude)) * COS(radians(35.6762)) *
                POWER(SIN((radians(139.6503) - radians(longitude)) / 2), 2)
            )
        ) as distance_km
    FROM locations
''').fetchall()

print(result)
```

**Result**: [('New York', 10851.73306683613), ('London', 9558.561322414535), ('Tokyo', 0.00012771038834187613)]

**Explanation**: Demonstrates geospatial calculations in DuckDB using Haversine formula to compute great-circle distances between geographic coordinates.
## Step 22: print(rel.execute().fetchall())

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')
conn.execute('CREATE TABLE numbers(x INTEGER)')
conn.executemany('INSERT INTO numbers VALUES (?)', [(i,) for i in range(10)])

rel = conn.sql('SELECT x FROM numbers WHERE x > 5')
print(rel.execute().fetchall())
```

**Result**: [('New York', 10851.73306683613), ('London', 9558.561322414535), ('Tokyo', 0.00012771038834187613)]

**Explanation**: Creates an in-memory table with numbers 0-9, then uses a relational algebra query to select and print numbers greater than 5, demonstrating basic DuckDB filtering and execution.
## Step 23: ```

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create a table with sensor temperature readings
conn.execute('CREATE TABLE temperature_readings (sensor_id INT, reading DECIMAL(5,2), timestamp TIMESTAMP)')
conn.executemany('INSERT INTO temperature_readings VALUES (?, ?, ?)', [
    (1, 22.5, '2023-07-15 10:00:00'),
    (1, 23.1, '2023-07-15 10:15:00'),
    (2, 21.8, '2023-07-15 10:00:00'),
    (2, 22.3, '2023-07-15 10:15:00')
])

# Use window function to calculate rolling average temperature per sensor
result = conn.execute('''
    SELECT 
        sensor_id, 
        reading, 
        timestamp,
        AVG(reading) OVER (PARTITION BY sensor_id ORDER BY timestamp ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) as rolling_avg
    FROM temperature_readings
''').fetchall()

print(result)
```

**Result**: [(1, Decimal('22.50'), datetime.datetime(2023, 7, 15, 10, 0), 22.5), (1, Decimal('23.10'), datetime.datetime(2023, 7, 15, 10, 15), 22.8), (2, Decimal('21.80'), datetime.datetime(2023, 7, 15, 10, 0), 21.8), (2, Decimal('22.30'), datetime.datetime(2023, 7, 15, 10, 15), 22.05)]

**Explanation**: Demonstrates a window function calculating a rolling temperature average for each sensor, partitioned by sensor_id and ordered by timestamp.
## Step 24: This example showcases DuckDB's LATERAL JOIN for dynamic, correlated subquery resolution.

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create products and discounts tables
conn.execute('CREATE TABLE products(product_id INT, name TEXT, price DECIMAL(10,2))')
conn.execute('CREATE TABLE discount_rules(min_price DECIMAL(10,2), discount_percentage DECIMAL(5,2))')

conn.executemany('INSERT INTO products VALUES (?, ?, ?)', [
    (1, 'Laptop', 1000.00),
    (2, 'Smartphone', 600.00),
    (3, 'Tablet', 400.00)
])

conn.executemany('INSERT INTO discount_rules VALUES (?, ?)', [
    (500.00, 10.0),
    (1000.00, 15.0)
])

# Use LATERAL JOIN to dynamically apply discounts
result = conn.execute('''
    SELECT 
        p.product_id, 
        p.name, 
        p.price, 
        d.discount_percentage,
        p.price * (1 - d.discount_percentage/100) as discounted_price
    FROM products p, LATERAL (
        SELECT discount_percentage 
        FROM discount_rules 
        WHERE p.price >= min_price 
        ORDER BY discount_percentage DESC 
        LIMIT 1
    ) d
''').fetchall()

print(result)
```

**Result**: [(2, 'Smartphone', Decimal('600.00'), Decimal('10.00'), 540.0), (1, 'Laptop', Decimal('1000.00'), Decimal('15.00'), 850.0)]

**Explanation**: Demonstrates DuckDB's LATERAL JOIN by dynamically applying the highest applicable discount to each product based on its price, allowing flexible, rule-based pricing calculations.
