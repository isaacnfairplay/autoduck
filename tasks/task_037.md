# Task: ```python
import duckdb

con = duckdb.connect()

# Demonstrate array_transform with modulo operation
rel = con.query('''
SELECT array_transform([10, 15, 20, 25], x -> x % 3) as remainder_array
''')

print(rel.execute().fetchall())
```

This concise example highlights DuckDB's array_transform function by applying a modulo operation, demonstrating its ability to perform element-wise transformations efficiently.

## Step 1: ```python

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create sample table with sales data
conn.execute('''
    CREATE TABLE sales (
        product_id INTEGER,
        sale_date DATE,
        quantity INTEGER,
        revenue DECIMAL(10,2)
    );

    INSERT INTO sales VALUES
        (1, '2023-01-15', 5, 250.50),
        (1, '2023-02-20', 3, 150.75),
        (2, '2023-01-10', 2, 100.25),
        (2, '2023-03-05', 7, 350.00);
''')

# Demonstrate window function: cumulative sales per product
result = conn.execute('''
    SELECT 
        product_id, 
        sale_date, 
        quantity,
        SUM(quantity) OVER (PARTITION BY product_id ORDER BY sale_date) as cumulative_quantity,
        SUM(revenue) OVER (PARTITION BY product_id ORDER BY sale_date) as cumulative_revenue
    FROM sales
    ORDER BY product_id, sale_date
''').fetchall()

for row in result:
    print(row)
```

**Result**: [(1, datetime.date(2023, 1, 15), 5, 5, Decimal('250.50')), (1, datetime.date(2023, 2, 20), 3, 8, Decimal('401.25')), (2, datetime.date(2023, 1, 10), 2, 2, Decimal('100.25')), (2, datetime.date(2023, 3, 5), 7, 9, Decimal('450.25'))]

**Explanation**: Demonstrates window functions in DuckDB by calculating cumulative sales quantity and revenue per product, partitioned and ordered chronologically.
## Step 2: import duckdb

**Generated by**: Anthropic

```python
import duckdb

# Create an in-memory connection
conn = duckdb.connect(':memory:')

# Create and populate inventory table
conn.execute('''
    CREATE TABLE inventory (
        product_id INTEGER,
        category TEXT,
        stock_quantity INTEGER,
        price DECIMAL(10,2)
    );

    INSERT INTO inventory VALUES
        (1, 'Electronics', 50, 129.99),
        (2, 'Clothing', 100, 49.50),
        (3, 'Books', 75, 19.99);
''')

# Analytical query with window functions and filtering
result = conn.execute('''
    SELECT 
        product_id, 
        category, 
        stock_quantity,
        RANK() OVER (ORDER BY stock_quantity DESC) as stock_rank,
        NTILE(3) OVER (ORDER BY price) as price_tier
    FROM inventory
    WHERE stock_quantity > 25
    ORDER BY stock_rank
''').fetchall()

for row in result:
    print(row)
```

**Result**: [(2, 'Clothing', 100, 1, 2), (3, 'Books', 75, 2, 1), (1, 'Electronics', 50, 3, 3)]

**Explanation**: Demonstrates DuckDB's window functions (RANK, NTILE) on an inventory table, showing stock ranking and price tiering with a simple filtering condition
## Step 3: con = duckdb.connect()

**Generated by**: Anthropic

```python
import duckdb

# Connect to an in-memory database
conn = duckdb.connect(':memory:')

# Create a temporary table of GitHub repositories
conn.execute("""
CREATE TABLE repositories (
    name TEXT,
    stars INTEGER,
    language TEXT,
    created_date DATE
);

INSERT INTO repositories VALUES
    ('duckdb', 7500, 'C++', '2019-01-01'),
    ('pandas', 33000, 'Python', '2012-01-15'),
    ('numpy', 22000, 'Python', '2005-11-03');
"""
)

# Complex query using window functions and aggregations
result = conn.execute("""
SELECT 
    language, 
    COUNT(*) as repo_count,
    AVG(stars) as avg_stars,
    RANK() OVER (ORDER BY AVG(stars) DESC) as star_rank
FROM repositories
GROUP BY language
ORDER BY avg_stars DESC
""").fetchall()

for row in result:
    print(row)
```

**Result**: [('Python', 2, 27500.0, 1), ('C++', 1, 7500.0, 2)]

**Explanation**: Demonstrates creating an in-memory table, performing a grouped window function query that calculates repository statistics by programming language, ranking languages by average stars
## Step 4: # Demonstrate array_transform with modulo operation

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create array and transform with modulo
result = conn.execute("""
    SELECT array_transform([10, 15, 20, 25], x -> x % 3) as transformed_array
""").fetchall()

print(result[0][0])  # Should output [1, 0, 2, 1]
```

**Result**: [([1, 0, 2, 1],)]

**Explanation**: Demonstrates DuckDB's array_transform function to apply a modulo operation across all elements of an input array, returning a new array with transformed values.
## Step 5: rel = con.query('''

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create table with complex nested data
conn.execute('''
CREATE TABLE product_details (
    product_id INTEGER,
    features STRUCT(color VARCHAR, size VARCHAR, material VARCHAR)
);

INSERT INTO product_details VALUES
    (1, {'color': 'red', 'size': 'large', 'material': 'cotton'}),
    (2, {'color': 'blue', 'size': 'medium', 'material': 'polyester'});
''')

# Extract nested struct fields
result = conn.execute('''
SELECT 
    product_id, 
    features.color as product_color,
    features.size as product_size
FROM product_details
''').fetchall()

for row in result:
    print(row)
```

**Result**: [(1, 'red', 'large'), (2, 'blue', 'medium')]

**Explanation**: Demonstrates DuckDB's support for nested STRUCT data types, showing how to create, insert, and query complex structured data with field extraction.
## Step 6: SELECT array_transform([10, 15, 20, 25], x -> x % 3) as remainder_array

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

result = conn.execute("SELECT array_transform([10, 15, 20, 25], x -> x % 3) as remainder_array").fetchall()

print(result[0][0])
```

**Result**: [([1, 0, 2, 1],)]

**Explanation**: Demonstrates DuckDB's array_transform() function, applying a modulo 3 operation to each element of the input array, returning the remainders [1, 0, 2, 1]
## Step 7: ''')

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create a time series table with daily temperature data
conn.execute('''
CREATE TABLE temperatures (
    date DATE,
    city TEXT,
    temp_celsius DECIMAL(5,2)
);

INSERT INTO temperatures VALUES
    ('2023-06-01', 'New York', 28.5),
    ('2023-06-02', 'New York', 30.2),
    ('2023-06-03', 'New York', 29.7),
    ('2023-06-01', 'London', 22.1),
    ('2023-06-02', 'London', 23.4),
    ('2023-06-03', 'London', 21.9);
''')

# Perform moving average calculation using window function
result = conn.execute('''
SELECT 
    city, 
    date, 
    temp_celsius,
    AVG(temp_celsius) OVER (PARTITION BY city ORDER BY date ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) as moving_avg
FROM temperatures
ORDER BY city, date
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('London', datetime.date(2023, 6, 1), Decimal('22.10'), 22.75), ('London', datetime.date(2023, 6, 2), Decimal('23.40'), 22.466666666666665), ('London', datetime.date(2023, 6, 3), Decimal('21.90'), 22.65), ('New York', datetime.date(2023, 6, 1), Decimal('28.50'), 29.35), ('New York', datetime.date(2023, 6, 2), Decimal('30.20'), 29.466666666666665), ('New York', datetime.date(2023, 6, 3), Decimal('29.70'), 29.95)]

**Explanation**: Demonstrates a time series analysis with a moving average window function, calculating 3-day rolling temperature averages for different cities using DuckDB's window function capabilities.
## Step 8: print(rel.execute().fetchall())

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create table
conn.execute('CREATE TABLE numbers (value INTEGER)')
conn.execute('INSERT INTO numbers VALUES (1), (2), (3), (4), (5)')

# Create a relation and execute
rel = conn.table('numbers').filter('value > 2')
print(rel.execute().fetchall())
```

**Result**: [('London', datetime.date(2023, 6, 1), Decimal('22.10'), 22.75), ('London', datetime.date(2023, 6, 2), Decimal('23.40'), 22.466666666666665), ('London', datetime.date(2023, 6, 3), Decimal('21.90'), 22.65), ('New York', datetime.date(2023, 6, 1), Decimal('28.50'), 29.35), ('New York', datetime.date(2023, 6, 2), Decimal('30.20'), 29.466666666666665), ('New York', datetime.date(2023, 6, 3), Decimal('29.70'), 29.95)]

**Explanation**: Demonstrates creating an in-memory table, using the relational API to filter rows, and executing the relation to fetch results
## Step 9: ```

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create geospatial data table with point coordinates
conn.execute('''
CREATE TABLE locations (
    city TEXT,
    latitude DECIMAL(8,6),
    longitude DECIMAL(9,6)
);

INSERT INTO locations VALUES
    ('New York', 40.712776, -74.005974),
    ('San Francisco', 37.774929, -122.419418),
    ('Chicago', 41.881832, -87.623177);
''')

# Query to calculate distance between cities
result = conn.execute('''
SELECT 
    l1.city as city1, 
    l2.city as city2,
    SQRT(POWER(l1.latitude - l2.latitude, 2) + POWER(l1.longitude - l2.longitude, 2)) as approximate_distance
FROM locations l1
CROSS JOIN locations l2
WHERE l1.city != l2.city
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('San Francisco', 'New York', 48.502499986459924), ('Chicago', 'New York', 13.667293421681741), ('New York', 'San Francisco', 48.502499986459924), ('Chicago', 'San Francisco', 35.03776591025019), ('New York', 'Chicago', 13.667293421681741), ('San Francisco', 'Chicago', 35.03776591025019)]

**Explanation**: Demonstrates creating a custom distance calculation between geographic points using a cross join and Euclidean distance approximation in DuckDB, showcasing spatial data manipulation and cross join capabilities.
## Step 10: This concise example highlights DuckDB's array_transform function by applying a modulo operation, demonstrating its ability to perform element-wise transformations efficiently.

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Demonstrate array_transform with modulo operation
result = conn.execute("""SELECT array_transform([10, 15, 20, 25], x -> x % 3) as transformed_array""").fetchall()

print(result[0][0])  # Outputs: [1, 0, 2, 1]
```

**Result**: [([1, 0, 2, 1],)]

**Explanation**: Uses DuckDB's array_transform function to apply a modulo 3 operation to each element of an array, showcasing functional array manipulation and element-wise transformations in a single SQL expression.
