# Task: I'll generate a targeted example demonstrating DuckDB's QUALIFY clause for advanced filtering with window functions:

```python
import duckdb

con = duckdb.connect()

# Create sales data
con.execute('''
CREATE TABLE product_sales AS
SELECT * FROM (VALUES
    ('Electronics', 'Laptop', 1200, '2023-01-01'),
    ('Electronics', 'Phone', 800, '2023-01-02'),
    ('Electronics', 'Tablet', 500, '2023-01-03'),
    ('Clothing', 'Shirt', 50, '2023-01-04'),
    ('Clothing', 'Pants', 100, '2023-01-05')
) AS t(category, product, amount, sale_date)
''')

# Use QUALIFY to filter top 2 products per category by sales
rel = con.query('''
SELECT *
FROM product_sales
QUALIFY ROW_NUMBER() OVER (PARTITION BY category ORDER BY amount DESC) <= 2
''')

print(rel.execute().fetchall())
```

This concise example showcases DuckDB's QUALIFY clause for filtering results using a window function ranking.

## Step 1: I'll generate a targeted example demonstrating DuckDB's QUALIFY clause for advanced filtering with window functions:

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create sample sales data
conn.execute('''
CREATE TABLE sales AS
SELECT * FROM (VALUES
    ('A', 100, '2023-01-01'),
    ('A', 200, '2023-02-01'),
    ('A', 150, '2023-03-01'),
    ('B', 120, '2023-01-01'),
    ('B', 180, '2023-02-01'),
    ('B', 220, '2023-03-01')
) AS t(region, amount, date);
'''
)

# Use QUALIFY to filter top 2 sales per region
result = conn.execute('''
SELECT region, amount, date,
       RANK() OVER (PARTITION BY region ORDER BY amount DESC) as sales_rank
FROM sales
QUALIFY sales_rank <= 2
''').fetchall()

print(result)
```

**Result**: [('B', 220, '2023-03-01', 1), ('B', 180, '2023-02-01', 2), ('A', 200, '2023-02-01', 1), ('A', 150, '2023-03-01', 2)]

**Explanation**: Demonstrates DuckDB's QUALIFY clause by ranking and filtering top 2 sales amounts per region using window function RANK()
## Step 2: ```python

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create sample customer orders
conn.execute('''
CREATE TABLE orders AS
SELECT * FROM (VALUES
    (1, 'John', 50.00, '2023-06-01'),
    (2, 'Jane', 75.50, '2023-06-02'),
    (3, 'Bob', 125.25, '2023-06-03'),
    (4, 'Alice', 200.00, '2023-06-04')
) AS t(order_id, customer, total, order_date);
''')

# Calculate running total with window function
result = conn.execute('''
SELECT 
    customer, 
    total, 
    order_date,
    SUM(total) OVER (ORDER BY order_date) as cumulative_sales
FROM orders
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('John', Decimal('50.00'), '2023-06-01', Decimal('50.00')), ('Jane', Decimal('75.50'), '2023-06-02', Decimal('125.50')), ('Bob', Decimal('125.25'), '2023-06-03', Decimal('250.75')), ('Alice', Decimal('200.00'), '2023-06-04', Decimal('450.75'))]

**Explanation**: Demonstrates DuckDB window function usage by calculating a running/cumulative total of sales, ordered chronologically across customer orders
## Step 3: import duckdb

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create sample employee data
conn.execute('''
CREATE TABLE employees AS
SELECT * FROM (VALUES
    (1, 'Alice', 'Sales', 50000),
    (2, 'Bob', 'Marketing', 60000),
    (3, 'Charlie', 'Sales', 55000),
    (4, 'David', 'Engineering', 75000)
) AS t(id, name, department, salary);
''')

# Use window function to calculate department-wise percentile rank of salaries
result = conn.execute('''SELECT 
    name, 
    department, 
    salary,
    NTILE(4) OVER (PARTITION BY department ORDER BY salary) as salary_quartile
FROM employees
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Alice', 'Sales', 50000, 1), ('Charlie', 'Sales', 55000, 2), ('David', 'Engineering', 75000, 1), ('Bob', 'Marketing', 60000, 1)]

**Explanation**: Demonstrates using window function NTILE() to calculate salary quartiles within each department, showcasing DuckDB's advanced analytical capabilities for ranking and segmenting data
## Step 4: con = duckdb.connect()

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create and populate product inventory table
conn.execute('''
CREATE TABLE inventory (
    product_id INT,
    product_name VARCHAR,
    category VARCHAR,
    stock_quantity INT
);

INSERT INTO inventory VALUES
    (1, 'Laptop', 'Electronics', 50),
    (2, 'Smartphone', 'Electronics', 100),
    (3, 'Headphones', 'Electronics', 75),
    (4, 'Desk Chair', 'Furniture', 30);
'''
)

# Demonstrate advanced window function: dense_rank() with filtering
result = conn.execute('''
SELECT 
    product_name, 
    category, 
    stock_quantity,
    DENSE_RANK() OVER (PARTITION BY category ORDER BY stock_quantity DESC) as stock_rank
FROM inventory
WHERE stock_quantity > 40
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Smartphone', 'Electronics', 100, 1), ('Headphones', 'Electronics', 75, 2), ('Laptop', 'Electronics', 50, 3)]

**Explanation**: Demonstrates advanced window function DENSE_RANK() with category partitioning, showing how to rank products by stock quantity within their category while filtering for high-stock items
## Step 5: # Create sales data

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create sales data with multiple attributes
conn.execute('''
CREATE TABLE regional_sales AS
SELECT * FROM (VALUES
    (1, 'North', 'Electronics', 5000, '2023-Q1'),
    (2, 'South', 'Clothing', 3500, '2023-Q1'),
    (3, 'East', 'Electronics', 4200, '2023-Q1'),
    (4, 'West', 'Furniture', 6000, '2023-Q1'),
    (5, 'North', 'Clothing', 2800, '2023-Q1')
) AS t(sale_id, region, category, revenue, quarter);
''')
```

**Result**: [('Smartphone', 'Electronics', 100, 1), ('Headphones', 'Electronics', 75, 2), ('Laptop', 'Electronics', 50, 3)]

**Explanation**: Creates an in-memory sales table with multi-dimensional data representing regional sales across different product categories, allowing for flexible analytical queries.
## Step 6: con.execute('''

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create multi-dimensional sales data
conn.execute('''
CREATE TABLE sales AS
SELECT * FROM (VALUES
    ('Electronics', 'North', 5000, '2023-Q1'),
    ('Clothing', 'South', 3500, '2023-Q1'),
    ('Electronics', 'East', 4200, '2023-Q1'),
    ('Furniture', 'West', 6000, '2023-Q1')
) AS t(category, region, revenue, quarter);
''')

# Demonstrate ROLLUP for multi-dimensional aggregation
result = conn.execute('''
SELECT 
    COALESCE(category, 'Total') as product_category,
    COALESCE(region, 'All Regions') as sales_region, 
    SUM(revenue) as total_revenue
FROM sales
GROUP BY ROLLUP(category, region)
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Electronics', 'All Regions', 9200), ('Furniture', 'All Regions', 6000), ('Total', 'All Regions', 18700), ('Electronics', 'North', 5000), ('Clothing', 'South', 3500), ('Furniture', 'West', 6000), ('Clothing', 'All Regions', 3500), ('Electronics', 'East', 4200)]

**Explanation**: Demonstrates DuckDB's ROLLUP functionality for hierarchical aggregation, generating subtotals across multiple dimensions (category and region) in a single query, showing nested aggregation levels.
## Step 7: CREATE TABLE product_sales AS

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('''
CREATE TABLE product_sales AS
SELECT * FROM (VALUES
    (1, 'Laptop', 'Electronics', 1200.50, 50),
    (2, 'Smartphone', 'Electronics', 800.25, 100),
    (3, 'Headphones', 'Electronics', 150.75, 75),
    (4, 'Desk Chair', 'Furniture', 350.00, 30),
    (5, 'Bookshelf', 'Furniture', 250.50, 20)
) AS t(product_id, product_name, category, price, stock_quantity);
''')
```

**Result**: [('Electronics', 'All Regions', 9200), ('Furniture', 'All Regions', 6000), ('Total', 'All Regions', 18700), ('Electronics', 'North', 5000), ('Clothing', 'South', 3500), ('Furniture', 'West', 6000), ('Clothing', 'All Regions', 3500), ('Electronics', 'East', 4200)]

**Explanation**: Creates an in-memory product sales table with multiple attributes including product ID, name, category, price, and stock quantity, demonstrating DuckDB's flexible table creation syntax
## Step 8: SELECT * FROM (VALUES

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create product sales data using VALUES clause
result = conn.execute('''
SELECT * FROM (VALUES
    (1, 'Laptop', 1200.50),
    (2, 'Smartphone', 800.25),
    (3, 'Headphones', 150.75)
) AS products(id, name, price)
''').fetchall()

for row in result:
    print(row)
```

**Result**: [(1, 'Laptop', Decimal('1200.50')), (2, 'Smartphone', Decimal('800.25')), (3, 'Headphones', Decimal('150.75'))]

**Explanation**: Demonstrates creating an inline table using VALUES clause, which allows quick data generation without explicit table creation. The clause defines a temporary result set with predefined data, useful for quick examples or testing.
## Step 9: ('Electronics', 'Laptop', 1200, '2023-01-01'),

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create electronics sales table
conn.execute('''
CREATE TABLE electronics_sales AS
SELECT * FROM (VALUES
    ('Electronics', 'Laptop', 1200, '2023-01-01'),
    ('Electronics', 'Smartphone', 800, '2023-02-01'),
    ('Electronics', 'Headphones', 200, '2023-03-01')
) AS t(category, product, price, sale_date);
''')

# Query to analyze electronics sales
result = conn.execute('''
SELECT 
    product, 
    SUM(price) as total_revenue,
    AVG(price) as avg_price
FROM electronics_sales
GROUP BY product
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Headphones', 200, 200.0), ('Laptop', 1200, 1200.0), ('Smartphone', 800, 800.0)]

**Explanation**: Creates an in-memory DuckDB table of electronics sales, demonstrates table creation with VALUES clause, and performs basic aggregation analysis showing total and average price per product
## Step 10: ('Electronics', 'Phone', 800, '2023-01-02'),

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create updated electronics sales table
conn.execute('''
CREATE TABLE electronics_sales AS
SELECT * FROM (VALUES
    ('Electronics', 'Laptop', 1200, '2023-01-01'),
    ('Electronics', 'Smartphone', 800, '2023-02-01'),
    ('Electronics', 'Headphones', 200, '2023-03-01'),
    ('Electronics', 'Phone', 800, '2023-01-02')
) AS t(category, product, price, sale_date);
''')

# Analyze sales with new product
result = conn.execute('''
SELECT 
    product, 
    SUM(price) as total_revenue,
    COUNT(*) as sales_count
FROM electronics_sales
GROUP BY product
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Smartphone', 800, 1), ('Phone', 800, 1), ('Laptop', 1200, 1), ('Headphones', 200, 1)]

**Explanation**: Added new 'Phone' product to electronics_sales table and modified query to include sales count alongside revenue calculation.
## Step 11: ('Electronics', 'Tablet', 500, '2023-01-03'),

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create electronics sales table with new data
conn.execute('''
CREATE TABLE electronics_sales AS
SELECT * FROM (VALUES
    ('Electronics', 'Laptop', 1200, '2023-01-01'),
    ('Electronics', 'Smartphone', 800, '2023-02-01'),
    ('Electronics', 'Headphones', 200, '2023-03-01'),
    ('Electronics', 'Tablet', 500, '2023-01-03')
) AS t(category, product, price, sale_date);
''')

# Analyze sales performance with new product
result = conn.execute('''
SELECT 
    product, 
    SUM(price) as total_revenue,
    AVG(price) as average_price,
    COUNT(*) as sales_count
FROM electronics_sales
GROUP BY product
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Headphones', 200, 200.0, 1), ('Laptop', 1200, 1200.0, 1), ('Smartphone', 800, 800.0, 1), ('Tablet', 500, 500.0, 1)]

**Explanation**: Extends previous electronics sales table by adding a new 'Tablet' product, demonstrates grouping and aggregation with a new data point, calculating total revenue, average price, and sales count per product
## Step 12: ('Clothing', 'Shirt', 50, '2023-01-04'),

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create clothing sales table with new product
conn.execute('''
CREATE TABLE clothing_sales AS
SELECT * FROM (VALUES
    ('Clothing', 'Shirt', 50, '2023-01-04'),
    ('Clothing', 'Pants', 75, '2023-02-01'),
    ('Clothing', 'Jacket', 120, '2023-03-15')
) AS t(category, product, price, sale_date);
''')

# Analyze clothing sales performance
result = conn.execute('''
SELECT 
    product, 
    SUM(price) as total_revenue,
    AVG(price) as average_price,
    COUNT(*) as sales_count
FROM clothing_sales
GROUP BY product
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Pants', 75, 75.0, 1), ('Shirt', 50, 50.0, 1), ('Jacket', 120, 120.0, 1)]

**Explanation**: Creates a clothing sales table with a new product, demonstrates aggregation using SQL to calculate total revenue, average price, and sales count for each product
## Step 13: ('Clothing', 'Pants', 100, '2023-01-05')

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('''
CREATE TABLE clothing_sales AS
SELECT * FROM (VALUES
    ('Clothing', 'Shirt', 50, '2023-01-04'),
    ('Clothing', 'Pants', 75, '2023-02-01'),
    ('Clothing', 'Jacket', 120, '2023-03-15'),
    ('Clothing', 'Pants', 100, '2023-01-05')
) AS t(category, product, price, sale_date);
''')

result = conn.execute('''
SELECT 
    product, 
    SUM(price) as total_revenue,
    AVG(price) as average_price,
    COUNT(*) as sales_count
FROM clothing_sales
WHERE product = 'Pants'
GROUP BY product
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Pants', 175, 87.5, 2)]

**Explanation**: The code adds the new ('Clothing', 'Pants', 100, '2023-01-05') record to the clothing_sales table and performs an aggregation specifically for the 'Pants' product, calculating total revenue, average price, and sales count.
## Step 14: ) AS t(category, product, amount, sale_date)

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('''
CREATE TABLE retail_sales AS
SELECT * FROM (VALUES
    ('Electronics', 'Laptop', 1200.50, '2023-01-15'),
    ('Electronics', 'Smartphone', 800.25, '2023-02-20'),
    ('Clothing', 'Shirt', 50.00, '2023-03-10'),
    ('Furniture', 'Chair', 250.75, '2023-04-05')
) AS t(category, product, amount, sale_date);
''')

# Aggregate sales by category with multi-column analysis
result = conn.execute('''
SELECT 
    category, 
    COUNT(*) as transaction_count,
    SUM(amount) as total_revenue,
    AVG(amount) as average_transaction
FROM retail_sales
GROUP BY category
ORDER BY total_revenue DESC
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Electronics', 2, Decimal('2000.75'), 1000.375), ('Furniture', 1, Decimal('250.75'), 250.75), ('Clothing', 1, Decimal('50.00'), 50.0)]

**Explanation**: Demonstrates creating a retail sales table with multi-category data and performing a complex GROUP BY aggregation to analyze sales performance across different product categories.
## Step 15: ''')

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create JSON-like nested data example
conn.execute('''
CREATE TABLE customer_orders (
    customer_id INT,
    orders STRUCT(product VARCHAR, quantity INT, price DECIMAL(10,2))[]
);

INSERT INTO customer_orders VALUES
    (1, [{'product': 'Laptop', 'quantity': 1, 'price': 1200.50}, {'product': 'Mouse', 'quantity': 2, 'price': 50.00}]),
    (2, [{'product': 'Monitor', 'quantity': 1, 'price': 300.75}]);
'''
)

# Query nested array data
result = conn.execute('''
SELECT 
    customer_id, 
    orders[1].product as first_product,
    ARRAY_LENGTH(orders) as total_orders
FROM customer_orders
''').fetchall()

for row in result:
    print(row)
```

**Result**: [(1, 'Laptop', 2), (2, 'Monitor', 1)]

**Explanation**: Demonstrates DuckDB's advanced support for nested array and struct data types, showing how to create, insert, and query complex JSON-like structured data within a relational context.
## Step 16: # Use QUALIFY to filter top 2 products per category by sales

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create sales data
conn.execute('''
CREATE TABLE product_sales AS
SELECT * FROM (VALUES
    ('Electronics', 'Laptop', 1200),
    ('Electronics', 'Smartphone', 800),
    ('Electronics', 'Headphones', 200),
    ('Electronics', 'Tablet', 500),
    ('Clothing', 'Shirt', 50),
    ('Clothing', 'Pants', 75),
    ('Clothing', 'Jacket', 120)
) AS t(category, product, sales);
''')

# Use QUALIFY to get top 2 products per category
result = conn.execute('''
SELECT category, product, sales,
       RANK() OVER (PARTITION BY category ORDER BY sales DESC) as sales_rank
FROM product_sales
QUALIFY sales_rank <= 2
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Electronics', 'Laptop', 1200, 1), ('Electronics', 'Smartphone', 800, 2), ('Clothing', 'Jacket', 120, 1), ('Clothing', 'Pants', 75, 2)]

**Explanation**: Demonstrates using QUALIFY with window function to filter top 2 products per category by sales, ranking and selecting the highest performing products within each category.
## Step 17: rel = con.query('''

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create employee hierarchy table
conn.execute('''
CREATE TABLE employees (
    id INT,
    name VARCHAR,
    manager_id INT
);

INSERT INTO employees VALUES
    (1, 'Alice', NULL),
    (2, 'Bob', 1),
    (3, 'Charlie', 1),
    (4, 'David', 2),
    (5, 'Eve', 3)
''')

# Recursive CTE to find reporting hierarchy
result = conn.execute('''
WITH RECURSIVE reporting_chain AS (
    SELECT id, name, manager_id, name AS path
    FROM employees WHERE manager_id IS NULL
    
    UNION ALL
    
    SELECT e.id, e.name, e.manager_id, rc.path || ' -> ' || e.name
    FROM employees e
    JOIN reporting_chain rc ON e.manager_id = rc.id
)
SELECT * FROM reporting_chain
''').fetchall()

for row in result:
    print(row)
```

**Result**: [(1, 'Alice', None, 'Alice'), (2, 'Bob', 1, 'Alice -> Bob'), (3, 'Charlie', 1, 'Alice -> Charlie'), (4, 'David', 2, 'Alice -> Bob -> David'), (5, 'Eve', 3, 'Alice -> Charlie -> Eve')]

**Explanation**: Demonstrates recursive Common Table Expression (CTE) to generate an organizational hierarchy, showing how employees report to managers in a nested, self-referential structure
## Step 18: SELECT *

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create simple products table
conn.execute('''
CREATE TABLE products AS SELECT * FROM (VALUES
    (1, 'Laptop', 1200.50),
    (2, 'Smartphone', 800.25),
    (3, 'Headphones', 150.75)
) AS t(id, name, price);
''')

# Perform simple SELECT * query
result = conn.execute('SELECT * FROM products').fetchall()

for row in result:
    print(row)
```

**Result**: [(1, 'Laptop', Decimal('1200.50')), (2, 'Smartphone', Decimal('800.25')), (3, 'Headphones', Decimal('150.75'))]

**Explanation**: Demonstrates a basic SELECT * query using DuckDB, creating an in-memory table and retrieving all rows and columns using the wildcard selector.
## Step 19: FROM product_sales

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create product sales table
conn.execute('''
CREATE TABLE product_sales AS
SELECT * FROM (VALUES
    ('Electronics', 'Laptop', 1200),
    ('Electronics', 'Smartphone', 800),
    ('Electronics', 'Headphones', 200),
    ('Clothing', 'Shirt', 50),
    ('Clothing', 'Pants', 75)
) AS t(category, product, sales);
''')

# Top products per category using window function
result = conn.execute('''
SELECT category, product, sales,
       RANK() OVER (PARTITION BY category ORDER BY sales DESC) as sales_rank
FROM product_sales
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Electronics', 'Laptop', 1200, 1), ('Electronics', 'Smartphone', 800, 2), ('Electronics', 'Headphones', 200, 3), ('Clothing', 'Pants', 75, 1), ('Clothing', 'Shirt', 50, 2)]

**Explanation**: Demonstrates creating a product sales table and using a window function (RANK) to analyze sales performance across different product categories, showing sales rank within each category.
## Step 20: QUALIFY ROW_NUMBER() OVER (PARTITION BY category ORDER BY amount DESC) <= 2

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create product sales table
conn.execute('''
CREATE TABLE product_sales AS
SELECT * FROM (VALUES
    ('Electronics', 'Laptop', 1200),
    ('Electronics', 'Smartphone', 800),
    ('Electronics', 'Headphones', 200),
    ('Clothing', 'Shirt', 50),
    ('Clothing', 'Pants', 75)
) AS t(category, product, amount);
''')

# Use ROW_NUMBER() with QUALIFY to get top 2 products per category
result = conn.execute('''
SELECT category, product, amount
FROM product_sales
QUALIFY ROW_NUMBER() OVER (PARTITION BY category ORDER BY amount DESC) <= 2
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Electronics', 'Laptop', 1200), ('Electronics', 'Smartphone', 800), ('Clothing', 'Pants', 75), ('Clothing', 'Shirt', 50)]

**Explanation**: Demonstrates using QUALIFY with ROW_NUMBER() to select top 2 products within each product category, ranking by sales/amount.
## Step 21: ''')

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create complex employee performance data
conn.execute('''
CREATE TABLE employee_performance AS
SELECT * FROM (VALUES
    (1, 'Alice', 'Sales', 100000, 85),
    (2, 'Bob', 'Marketing', 90000, 75),
    (3, 'Charlie', 'Sales', 95000, 90),
    (4, 'David', 'Engineering', 120000, 95)
) AS t(id, name, department, salary, performance_score);
''')

# Use WINDOW function to calculate relative performance
result = conn.execute('''
SELECT
    name,
    department,
    salary,
    performance_score,
    PERCENT_RANK() OVER (PARTITION BY department ORDER BY performance_score) as performance_percentile
FROM employee_performance
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Alice', 'Sales', 100000, 85, 0.0), ('Charlie', 'Sales', 95000, 90, 1.0), ('David', 'Engineering', 120000, 95, 0.0), ('Bob', 'Marketing', 90000, 75, 0.0)]

**Explanation**: Demonstrates advanced window function PERCENT_RANK() to calculate performance percentile within each department, showing relative employee performance contextualized by their departmental peers.
## Step 22: print(rel.execute().fetchall())

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('CREATE TABLE sample_data (id INT, value VARCHAR)')
conn.execute("INSERT INTO sample_data VALUES (1, 'hello'), (2, 'world')")

rel = conn.table('sample_data').filter('id = 1')
print(rel.execute().fetchall())
```

**Result**: [('Alice', 'Sales', 100000, 85, 0.0), ('Charlie', 'Sales', 95000, 90, 1.0), ('David', 'Engineering', 120000, 95, 0.0), ('Bob', 'Marketing', 90000, 75, 0.0)]

**Explanation**: Creates an in-memory table with sample data, uses relational API to filter rows with id=1, and prints the result.
## Step 23: ```

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create a complex employee performance tracking system
conn.execute('''
CREATE TABLE employee_performance (
    employee_id INT,
    name VARCHAR,
    department VARCHAR,
    salary DECIMAL(10,2),
    performance_score INT,
    years_of_service INT
);

INSERT INTO employee_performance VALUES
    (1, 'Alice', 'Sales', 100000.00, 95, 5),
    (2, 'Bob', 'Marketing', 85000.00, 88, 3),
    (3, 'Charlie', 'Engineering', 120000.00, 92, 7);
'''
)

# Advanced window function analysis with multi-criteria ranking
result = conn.execute('''
SELECT
    name,
    department,
    salary,
    performance_score,
    years_of_service,
    DENSE_RANK() OVER (PARTITION BY department ORDER BY performance_score DESC) as performance_rank,
    PERCENT_RANK() OVER (ORDER BY salary) as salary_percentile
FROM employee_performance
''').fetchall()

for row in result:
    print(row)

```

**Result**: [('Bob', 'Marketing', Decimal('85000.00'), 88, 3, 1, 0.0), ('Alice', 'Sales', Decimal('100000.00'), 95, 5, 1, 0.5), ('Charlie', 'Engineering', Decimal('120000.00'), 92, 7, 1, 1.0)]

**Explanation**: Demonstrates DuckDB's advanced window function capabilities by creating a multi-dimensional employee performance analysis that ranks employees by performance within departments and calculates their salary percentile across the entire organization.
## Step 24: This concise example showcases DuckDB's QUALIFY clause for filtering results using a window function ranking.

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create product sales data
conn.execute('''
CREATE TABLE product_sales AS
SELECT * FROM (VALUES
    ('Electronics', 'Laptop', 1200),
    ('Electronics', 'Smartphone', 800),
    ('Electronics', 'Headphones', 200),
    ('Clothing', 'Shirt', 50),
    ('Clothing', 'Pants', 75)
) AS t(category, product, sales);
''')

# Use QUALIFY to get top 2 products per category
result = conn.execute('''
SELECT category, product, sales,
       RANK() OVER (PARTITION BY category ORDER BY sales DESC) as sales_rank
FROM product_sales
QUALIFY sales_rank <= 2
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Electronics', 'Laptop', 1200, 1), ('Electronics', 'Smartphone', 800, 2), ('Clothing', 'Pants', 75, 1), ('Clothing', 'Shirt', 50, 2)]

**Explanation**: Demonstrates using QUALIFY with a window function to filter and rank products within each category, retrieving the top 2 selling products per product category.
