# Task: I'll create a focused example demonstrating DuckDB's window functions in the relational API, calculating cumulative sales and ranking products within categories:

```python
import duckdb

# Create connection
con = duckdb.connect()

# Sample sales data
con.execute('''
CREATE TABLE sales AS 
SELECT * FROM (VALUES 
    ('Electronics', 'Laptop', 1200),
    ('Electronics', 'Phone', 800),
    ('Clothing', 'Shirt', 50),
    ('Clothing', 'Pants', 100),
    ('Electronics', 'Tablet', 500)
) AS t(category, product, sale_amount)
''')

# Create relation and apply window functions
rel = con.query('''
SELECT 
    category, 
    product, 
    sale_amount,
    SUM(sale_amount) OVER (PARTITION BY category ORDER BY sale_amount) as cumulative_category_sales,
    RANK() OVER (PARTITION BY category ORDER BY sale_amount DESC) as product_rank
FROM sales
''')

# Execute and display results
print(rel.execute().fetchall())
```

This example demonstrates window functions in the DuckDB relational API by calculating cumulative sales per category and ranking products within each category.

## Step 1: I'll create a focused example demonstrating DuckDB's window functions in the relational API, calculating cumulative sales and ranking products within categories:

**Generated by**: Anthropic

```python
import duckdb

# Create an in-memory database
conn = duckdb.connect(':memory:')

# Create a sample sales dataset
conn.execute('''
CREATE TABLE product_sales (
    category VARCHAR,
    product VARCHAR,
    sales_amount DECIMAL(10,2)
);

INSERT INTO product_sales VALUES 
    ('Electronics', 'Laptop', 1200.50),
    ('Electronics', 'Smartphone', 800.25),
    ('Clothing', 'Jacket', 250.75),
    ('Clothing', 'Shoes', 150.00),
    ('Electronics', 'Tablet', 500.00);
''')

# Window function analysis: cumulative sales and product ranking within category
result = conn.execute('''
SELECT 
    category, 
    product, 
    sales_amount,
    SUM(sales_amount) OVER (PARTITION BY category ORDER BY sales_amount) as cumulative_category_sales,
    RANK() OVER (PARTITION BY category ORDER BY sales_amount DESC) as product_rank
FROM product_sales
ORDER BY category, product_rank
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Clothing', 'Jacket', Decimal('250.75'), Decimal('400.75'), 1), ('Clothing', 'Shoes', Decimal('150.00'), Decimal('150.00'), 2), ('Electronics', 'Laptop', Decimal('1200.50'), Decimal('2500.75'), 1), ('Electronics', 'Smartphone', Decimal('800.25'), Decimal('1300.25'), 2), ('Electronics', 'Tablet', Decimal('500.00'), Decimal('500.00'), 3)]

**Explanation**: Demonstrates DuckDB window functions by calculating cumulative sales within product categories and ranking products by sales amount, showcasing partitioning and ranking capabilities.
## Step 2: ```python

**Generated by**: Anthropic

```python
import duckdb

# Create an in-memory database and connect
conn = duckdb.connect(':memory:')

# Create a sensor temperature dataset with timestamps
conn.execute('''
CREATE TABLE sensor_data (
    sensor_id INTEGER,
    timestamp TIMESTAMP,
    temperature DECIMAL(5,2)
);

INSERT INTO sensor_data VALUES
    (1, '2023-06-01 10:00:00', 22.5),
    (1, '2023-06-01 11:00:00', 23.1),
    (2, '2023-06-01 10:00:00', 21.8),
    (2, '2023-06-01 11:00:00', 22.3);
''')

# Use window functions to compute rolling average and temperature change
result = conn.execute('''
SELECT 
    sensor_id, 
    timestamp,
    temperature,
    AVG(temperature) OVER (PARTITION BY sensor_id ORDER BY timestamp ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) as rolling_avg,
    temperature - LAG(temperature) OVER (PARTITION BY sensor_id ORDER BY timestamp) as temp_change
FROM sensor_data
''').fetchall()

for row in result:
    print(row)
```

**Result**: [(1, datetime.datetime(2023, 6, 1, 10, 0), Decimal('22.50'), 22.5, None), (1, datetime.datetime(2023, 6, 1, 11, 0), Decimal('23.10'), 22.8, Decimal('0.60')), (2, datetime.datetime(2023, 6, 1, 10, 0), Decimal('21.80'), 21.8, None), (2, datetime.datetime(2023, 6, 1, 11, 0), Decimal('22.30'), 22.05, Decimal('0.50'))]

**Explanation**: Demonstrates advanced window function usage with sensor temperature data, showing rolling average calculation and temperature change tracking per sensor over time.
## Step 3: import duckdb

**Generated by**: Anthropic

```python
import duckdb

# Create an in-memory database
conn = duckdb.connect(':memory:')

# Create tables for employees and departments
conn.execute('''
CREATE TABLE employees (
    id INT,
    name VARCHAR,
    department_id INT,
    salary DECIMAL(10,2)
);

CREATE TABLE departments (
    id INT,
    name VARCHAR
);

INSERT INTO employees VALUES
    (1, 'Alice', 1, 5000.00),
    (2, 'Bob', 2, 6000.00),
    (3, 'Charlie', 1, 5500.00);

INSERT INTO departments VALUES
    (1, 'Sales'),
    (2, 'Engineering');
''');

# Perform a complex join with aggregation and subquery
result = conn.execute('''
SELECT 
    d.name AS department, 
    AVG(e.salary) AS avg_salary,
    COUNT(*) AS employee_count
FROM employees e
JOIN departments d ON e.department_id = d.id
GROUP BY d.name
HAVING AVG(e.salary) > (
    SELECT AVG(salary) FROM employees
)
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Engineering', 6000.0, 1)]

**Explanation**: Demonstrates a multi-table join with department and employee data, using subquery in HAVING clause to filter departments with above-average salaries, and performing aggregate calculations
## Step 4: # Create connection

**Generated by**: Anthropic

```python
import duckdb

# Create an in-memory database connection
conn = duckdb.connect(':memory:')

# Create a table for online orders
conn.execute('''
CREATE TABLE orders (
    order_id INTEGER,
    customer_id INTEGER,
    product_name VARCHAR,
    order_date DATE,
    total_amount DECIMAL(10,2)
);

INSERT INTO orders VALUES
    (1, 101, 'Laptop', '2023-06-15', 1200.50),
    (2, 102, 'Smartphone', '2023-06-16', 800.25),
    (3, 101, 'Headphones', '2023-06-17', 150.00);
'''
)

# Perform a query with multiple window functions
result = conn.execute('''
SELECT 
    customer_id,
    order_date,
    total_amount,
    SUM(total_amount) OVER (PARTITION BY customer_id ORDER BY order_date) as cumulative_spend,
    RANK() OVER (ORDER BY total_amount DESC) as order_rank
FROM orders
''').fetchall()

for row in result:
    print(row)
```

**Result**: [(101, datetime.date(2023, 6, 15), Decimal('1200.50'), Decimal('1200.50'), 1), (102, datetime.date(2023, 6, 16), Decimal('800.25'), Decimal('800.25'), 2), (101, datetime.date(2023, 6, 17), Decimal('150.00'), Decimal('1350.50'), 3)]

**Explanation**: Demonstrates creating an in-memory DuckDB database with orders, using window functions to analyze customer spending and order ranking across different dates and amounts.
## Step 5: con = duckdb.connect()

**Generated by**: Anthropic

```python
import duckdb

# Create in-memory connection
conn = duckdb.connect(':memory:')

# Create a table with geographic data
conn.execute('''
CREATE TABLE cities (
    city VARCHAR,
    country VARCHAR,
    population INTEGER
);

INSERT INTO cities VALUES
    ('New York', 'USA', 8400000),
    ('London', 'UK', 9000000),
    ('Tokyo', 'Japan', 14000000);
''')

# Perform aggregation and filtering
result = conn.execute('''
SELECT 
    country, 
    MAX(population) as max_population,
    COUNT(*) as city_count
FROM cities
GROUP BY country
HAVING MAX(population) > 5000000
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('UK', 9000000, 1), ('Japan', 14000000, 1), ('USA', 8400000, 1)]

**Explanation**: Demonstrates creating an in-memory DuckDB database with cities, performing group-level aggregation, and filtering by population threshold using SQL
## Step 6: # Sample sales data

**Generated by**: Anthropic

```python
import duckdb

# Create in-memory database
conn = duckdb.connect(':memory:')

# Create sales dataset
conn.execute('''
CREATE TABLE sales (
    product VARCHAR,
    category VARCHAR,
    quantity INTEGER,
    price DECIMAL(10,2)
);

INSERT INTO sales VALUES
    ('Laptop', 'Electronics', 10, 1200.50),
    ('Smartphone', 'Electronics', 15, 800.25),
    ('Shoes', 'Clothing', 20, 150.00);
''')

# Analyze total sales by category
result = conn.execute('''
SELECT 
    category, 
    SUM(quantity * price) as total_revenue,
    AVG(price) as avg_price
FROM sales
GROUP BY category
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Electronics', Decimal('24008.75'), 1000.375), ('Clothing', Decimal('3000.00'), 150.0)]

**Explanation**: Demonstrates creating a sales table, inserting sample data, and performing grouped aggregation to calculate total revenue and average price by product category using DuckDB's SQL capabilities.
## Step 7: con.execute('''

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

# Create a table of student test scores
conn.execute('''
CREATE TABLE student_scores (
    student_id INT,
    subject VARCHAR,
    score DECIMAL(5,2)
);

INSERT INTO student_scores VALUES
    (1, 'Math', 85.5),
    (1, 'Science', 92.0),
    (2, 'Math', 78.5),
    (2, 'Science', 88.0);
''')

# Use PIVOT to transform subject scores into columns
result = conn.execute('''
SELECT 
    student_id,
    MAX(CASE WHEN subject = 'Math' THEN score END) as math_score,
    MAX(CASE WHEN subject = 'Science' THEN score END) as science_score
FROM student_scores
GROUP BY student_id
''').fetchall()

for row in result:
    print(row)
```

**Result**: [(1, Decimal('85.50'), Decimal('92.00')), (2, Decimal('78.50'), Decimal('88.00'))]

**Explanation**: Demonstrates using a PIVOT-like technique with conditional aggregation to transform rows into columns, showing how to restructure data using SQL and DuckDB's flexible querying capabilities.
## Step 8: CREATE TABLE sales AS

**Generated by**: Anthropic

```python
import duckdb

# Create an in-memory database connection
conn = duckdb.connect(':memory:')

# Create sales table using CREATE TABLE AS with a derived query
conn.execute('''CREATE TABLE sales AS
SELECT
    'Laptop' as product,
    'Electronics' as category,
    10 as quantity,
    1200.50 as price
UNION ALL
SELECT
    'Smartphone' as product,
    'Electronics' as category,
    15 as quantity,
    800.25 as price
UNION ALL
SELECT
    'Shoes' as product,
    'Clothing' as category,
    20 as quantity,
    150.00 as price
''')

# Verify table creation
result = conn.execute('SELECT * FROM sales').fetchall()
for row in result:
    print(row)
```

**Result**: [('Laptop', 'Electronics', 10, Decimal('1200.50')), ('Smartphone', 'Electronics', 15, Decimal('800.25')), ('Shoes', 'Clothing', 20, Decimal('150.00'))]

**Explanation**: Demonstrates DuckDB's CREATE TABLE AS syntax by creating a sales table from a derived query, allowing inline table generation without separate INSERT statements.
## Step 9: SELECT * FROM (VALUES

**Generated by**: Anthropic

```python
import duckdb

# Create in-memory database
conn = duckdb.connect(':memory:')

# Generate table directly from VALUES clause
result = conn.execute('''
SELECT * FROM (VALUES
    ('Apple', 10),
    ('Banana', 15),
    ('Cherry', 20)
) AS fruits(name, quantity)
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Apple', 10), ('Banana', 15), ('Cherry', 20)]

**Explanation**: Demonstrates DuckDB's ability to create an inline table using the VALUES clause, which allows direct table generation without a separate CREATE TABLE statement. This technique is useful for quick data generation, testing, or inline data transformations.
## Step 10: ('Electronics', 'Laptop', 1200),

**Generated by**: Anthropic

```python
import duckdb

# Create in-memory database
conn = duckdb.connect(':memory:')

# Create and populate product sales table
conn.execute('''
CREATE TABLE product_sales (
    category VARCHAR,
    product VARCHAR,
    sales_amount DECIMAL(10,2)
);

INSERT INTO product_sales VALUES
    ('Electronics', 'Laptop', 1200.00);
''')

# Query specific electronics product
result = conn.execute('''
SELECT * FROM product_sales
WHERE category = 'Electronics' AND product = 'Laptop'
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Electronics', 'Laptop', Decimal('1200.00'))]

**Explanation**: Demonstrates creating an in-memory database, defining a product sales table, inserting an electronics product record, and querying for specific category and product conditions using DuckDB.
## Step 11: ('Electronics', 'Phone', 800),

**Generated by**: Anthropic

```python
import duckdb

# Create in-memory database
conn = duckdb.connect(':memory:')

# Create and populate product sales table
conn.execute('''
CREATE TABLE product_sales (
    category VARCHAR,
    product VARCHAR,
    sales_amount DECIMAL(10,2)
);

INSERT INTO product_sales VALUES
    ('Electronics', 'Laptop', 1200.00),
    ('Electronics', 'Phone', 800.00);
''')

# Query specific electronics product
result = conn.execute('''
SELECT * FROM product_sales
WHERE category = 'Electronics' AND product = 'Phone'
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Electronics', 'Phone', Decimal('800.00'))]

**Explanation**: This code demonstrates creating a product sales table in DuckDB, inserting two electronics products, and then querying specifically for the 'Phone' product in the 'Electronics' category.
## Step 12: ('Clothing', 'Shirt', 50),

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('''
CREATE TABLE product_sales (
    category VARCHAR,
    product VARCHAR,
    sales_amount DECIMAL(10,2)
);

INSERT INTO product_sales VALUES
    ('Clothing', 'Shirt', 50.00);
''')

result = conn.execute('''
SELECT * FROM product_sales
WHERE category = 'Clothing' AND product = 'Shirt'
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Clothing', 'Shirt', Decimal('50.00'))]

**Explanation**: Demonstrates creating an in-memory DuckDB database, inserting a clothing product record, and querying for a specific clothing item using SQL filtering conditions.
## Step 13: ('Clothing', 'Pants', 100),

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('''
CREATE TABLE product_sales (
    category VARCHAR,
    product VARCHAR,
    sales_amount DECIMAL(10,2)
);

INSERT INTO product_sales VALUES
    ('Clothing', 'Shirt', 50.00),
    ('Clothing', 'Pants', 100.00);
''')

result = conn.execute('''
SELECT * FROM product_sales
WHERE category = 'Clothing' AND product = 'Pants'
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Clothing', 'Pants', Decimal('100.00'))]

**Explanation**: Creates an in-memory database with a product_sales table, inserts clothing items, and queries specifically for clothing pants, demonstrating basic DuckDB filtering and table creation
## Step 14: ('Electronics', 'Tablet', 500)

**Generated by**: Anthropic

```python
import duckdb

# Create in-memory database
conn = duckdb.connect(':memory:')

# Create product sales table with Electronics and Tablet
conn.execute('''
CREATE TABLE product_sales (
    category VARCHAR,
    product VARCHAR,
    sales_amount DECIMAL(10,2)
);

INSERT INTO product_sales VALUES
    ('Electronics', 'Tablet', 500.00);
''')

# Query Electronics Tablet
result = conn.execute('''
SELECT * FROM product_sales
WHERE category = 'Electronics' AND product = 'Tablet'
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Electronics', 'Tablet', Decimal('500.00'))]

**Explanation**: This code creates an in-memory DuckDB database with a product_sales table, inserts an Electronics Tablet record with $500 sales amount, and queries for that specific product.
## Step 15: ) AS t(category, product, sale_amount)

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('''
CREATE TABLE product_sales AS
SELECT * FROM (VALUES
    ('Electronics', 'Tablet', 500.00)
) AS t(category, product, sale_amount)
''')

result = conn.execute('SELECT * FROM product_sales').fetchall()
for row in result:
    print(row)
```

**Result**: [('Electronics', 'Tablet', Decimal('500.00'))]

**Explanation**: Demonstrates creating a table from VALUES clause with a single electronics product, showing how to directly populate a table from an inline data specification in DuckDB
## Step 16: ''')

**Generated by**: Anthropic

```python
import duckdb

# Create in-memory database
conn = duckdb.connect(':memory:')

# Create JSON processing table
conn.execute('''
CREATE TABLE customer_data (
    id INTEGER,
    details JSON
);

INSERT INTO customer_data VALUES
    (1, '{ "name": "Alice", "age": 30, "city": "New York" }'),
    (2, '{ "name": "Bob", "age": 45, "city": "Chicago" }');
''')  

# Extract and query JSON data
result = conn.execute('''
SELECT 
    id, 
    details->>'name' as name,
    details->>'age' as age,
    details->>'city' as city
FROM customer_data
WHERE (details->>'age')::INTEGER > 35
''').fetchall()

for row in result:
    print(row)
```

**Result**: [(2, 'Bob', '45', 'Chicago')]

**Explanation**: Demonstrates DuckDB's native JSON processing capabilities by creating a table with JSON data, extracting nested properties, and performing filtering on JSON attributes.
## Step 17: # Create relation and apply window functions

**Generated by**: Anthropic

```python
import duckdb

# Create in-memory database
conn = duckdb.connect(':memory:')

# Create customer order table
conn.execute('''
CREATE TABLE customer_orders (
    customer_id INTEGER,
    order_date DATE,
    order_amount DECIMAL(10,2)
);

INSERT INTO customer_orders VALUES
    (1, '2023-01-15', 250.50),
    (1, '2023-02-20', 350.75),
    (2, '2023-01-10', 175.25),
    (2, '2023-03-05', 275.00);
''')

# Apply window functions for cumulative and ranked analysis
result = conn.execute('''
SELECT
    customer_id,
    order_date,
    order_amount,
    SUM(order_amount) OVER (PARTITION BY customer_id ORDER BY order_date) as cumulative_spend,
    RANK() OVER (ORDER BY order_amount DESC) as order_rank
FROM customer_orders
''').fetchall()

for row in result:
    print(row)
```

**Result**: [(1, datetime.date(2023, 2, 20), Decimal('350.75'), Decimal('601.25'), 1), (2, datetime.date(2023, 3, 5), Decimal('275.00'), Decimal('450.25'), 2), (1, datetime.date(2023, 1, 15), Decimal('250.50'), Decimal('250.50'), 3), (2, datetime.date(2023, 1, 10), Decimal('175.25'), Decimal('175.25'), 4)]

**Explanation**: Demonstrates window functions in DuckDB by computing cumulative customer spend and ranking orders by amount. Shows partitioning, cumulative aggregation, and ranking capabilities.
## Step 18: rel = con.query('''

**Generated by**: Anthropic

```python
import duckdb

# Create in-memory database
conn = duckdb.connect(':memory:')

# Create sensor temperature dataset with temporal data
conn.execute('''
CREATE TABLE sensor_readings (
    sensor_id INTEGER,
    timestamp TIMESTAMP,
    temperature DECIMAL(5,2)
);

INSERT INTO sensor_readings VALUES
    (1, '2023-07-15 10:00:00', 22.5),
    (1, '2023-07-15 11:00:00', 23.1),
    (2, '2023-07-15 10:00:00', 21.8);
''')

# Analyze temperature trends with window functions
result = conn.execute('''
SELECT
    sensor_id,
    timestamp,
    temperature,
    AVG(temperature) OVER (PARTITION BY sensor_id ORDER BY timestamp ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) as rolling_avg
FROM sensor_readings
''').fetchall()

for row in result:
    print(row)
```

**Result**: [(1, datetime.datetime(2023, 7, 15, 10, 0), Decimal('22.50'), 22.5), (1, datetime.datetime(2023, 7, 15, 11, 0), Decimal('23.10'), 22.8), (2, datetime.datetime(2023, 7, 15, 10, 0), Decimal('21.80'), 21.8)]

**Explanation**: Demonstrates DuckDB's window function capabilities by computing a rolling average temperature for sensor readings across different timestamps, showcasing temporal data analysis with partitioning and windowing.
## Step 19: SELECT

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('''
CREATE TABLE products (
    product_id INT,
    name VARCHAR,
    price DECIMAL(10,2)
);

INSERT INTO products VALUES
    (1, 'Laptop', 1200.50),
    (2, 'Smartphone', 800.25),
    (3, 'Tablet', 500.00);
''')

result = conn.execute('''
SELECT name, price
FROM products
WHERE price > 600
ORDER BY price DESC
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Laptop', Decimal('1200.50')), ('Smartphone', Decimal('800.25'))]

**Explanation**: Demonstrates basic SELECT query with filtering and ordering on a products table, retrieving product names and prices for items over $600, sorted in descending price order.
## Step 20: category,

**Generated by**: Anthropic

```python
import duckdb

# Create in-memory database
conn = duckdb.connect(':memory:')

# Create product sales table with category focus
conn.execute('''
CREATE TABLE product_sales (
    category VARCHAR,
    product VARCHAR,
    sales_amount DECIMAL(10,2)
);

INSERT INTO product_sales VALUES
    ('Electronics', 'Laptop', 1200.50),
    ('Electronics', 'Smartphone', 800.25),
    ('Clothing', 'Jacket', 250.75);
''')

# Analyze sales by category
result = conn.execute('''
SELECT 
    category, 
    COUNT(*) as product_count,
    SUM(sales_amount) as total_category_sales,
    AVG(sales_amount) as avg_category_sales
FROM product_sales
GROUP BY category
ORDER BY total_category_sales DESC
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Electronics', 2, Decimal('2000.75'), 1000.375), ('Clothing', 1, Decimal('250.75'), 250.75)]

**Explanation**: Demonstrates category-level sales analysis using DuckDB, showing product count, total sales, and average sale price per category with basic aggregation and grouping.
## Step 21: product,

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('''
CREATE TABLE products (
    product_id INT,
    name VARCHAR,
    price DECIMAL(10,2),
    category VARCHAR
);

INSERT INTO products VALUES
    (1, 'Laptop', 1200.50, 'Electronics'),
    (2, 'Smartphone', 800.25, 'Electronics'),
    (3, 'Tablet', 500.00, 'Electronics');
''')

result = conn.execute('''
SELECT name, price, category
FROM products
WHERE category = 'Electronics'
ORDER BY price DESC
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Laptop', Decimal('1200.50'), 'Electronics'), ('Smartphone', Decimal('800.25'), 'Electronics'), ('Tablet', Decimal('500.00'), 'Electronics')]

**Explanation**: Demonstrates creating a product table, inserting records, and performing a filtered query on Electronics products sorted by price in descending order.
## Step 22: sale_amount,

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('''
CREATE TABLE product_sales (
    category VARCHAR,
    product VARCHAR,
    sale_amount DECIMAL(10,2)
);

INSERT INTO product_sales VALUES
    ('Electronics', 'Laptop', 1200.50),
    ('Electronics', 'Smartphone', 800.25),
    ('Clothing', 'Jacket', 250.75);
''')

result = conn.execute('''
SELECT category, SUM(sale_amount) as total_sales
FROM product_sales
GROUP BY category
ORDER BY total_sales DESC
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Electronics', Decimal('2000.75')), ('Clothing', Decimal('250.75'))]

**Explanation**: Demonstrates creating an in-memory table of product sales, performing a grouped aggregation to calculate total sales by category, and ordering results from highest to lowest sales.
## Step 23: SUM(sale_amount) OVER (PARTITION BY category ORDER BY sale_amount) as cumulative_category_sales,

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('''
CREATE TABLE product_sales (
    category VARCHAR,
    product VARCHAR,
    sale_amount DECIMAL(10,2)
);

INSERT INTO product_sales VALUES
    ('Electronics', 'Laptop', 1200.50),
    ('Electronics', 'Smartphone', 800.25),
    ('Clothing', 'Jacket', 250.75);
''')

result = conn.execute('''
SELECT 
    category, 
    product, 
    sale_amount,
    SUM(sale_amount) OVER (PARTITION BY category ORDER BY sale_amount) as cumulative_category_sales
FROM product_sales
ORDER BY category, cumulative_category_sales
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Clothing', 'Jacket', Decimal('250.75'), Decimal('250.75')), ('Electronics', 'Smartphone', Decimal('800.25'), Decimal('800.25')), ('Electronics', 'Laptop', Decimal('1200.50'), Decimal('2000.75'))]

**Explanation**: Demonstrates a window function that calculates cumulative sales within each product category, progressively summing sale amounts ordered by sale amount. Helps visualize sales accumulation across different categories.
## Step 24: RANK() OVER (PARTITION BY category ORDER BY sale_amount DESC) as product_rank

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('''
CREATE TABLE product_sales (
    category VARCHAR,
    product VARCHAR,
    sale_amount DECIMAL(10,2)
);

INSERT INTO product_sales VALUES
    ('Electronics', 'Laptop', 1200.50),
    ('Electronics', 'Smartphone', 800.25),
    ('Clothing', 'Jacket', 250.75);
''')

result = conn.execute('''
SELECT 
    category, 
    product, 
    sale_amount,
    RANK() OVER (PARTITION BY category ORDER BY sale_amount DESC) as product_rank
FROM product_sales
ORDER BY category, product_rank
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Clothing', 'Jacket', Decimal('250.75'), 1), ('Electronics', 'Laptop', Decimal('1200.50'), 1), ('Electronics', 'Smartphone', Decimal('800.25'), 2)]

**Explanation**: This example demonstrates using the RANK() window function to rank products within each category based on their sales amount. Products are ranked from highest to lowest sales within their respective category, showing how window functions can provide ranking insights across partitioned data.
## Step 25: FROM sales

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('''
CREATE TABLE sales (
    product VARCHAR,
    category VARCHAR,
    quantity INTEGER,
    price DECIMAL(10,2)
);

INSERT INTO sales VALUES
    ('Laptop', 'Electronics', 10, 1200.50),
    ('Smartphone', 'Electronics', 15, 800.25),
    ('Shoes', 'Clothing', 20, 150.00);
''')

result = conn.execute('SELECT * FROM sales').fetchall()
for row in result:
    print(row)
```

**Result**: [('Laptop', 'Electronics', 10, Decimal('1200.50')), ('Smartphone', 'Electronics', 15, Decimal('800.25')), ('Shoes', 'Clothing', 20, Decimal('150.00'))]

**Explanation**: Creates an in-memory sales table and retrieves all records using DuckDB's simple table creation and SELECT pattern
## Step 26: ''')

**Generated by**: Anthropic

```python
import duckdb

# Create an in-memory database
conn = duckdb.connect(':memory:')

# Create sales performance tracking table
conn.execute('''
CREATE TABLE sales_performance (
    product VARCHAR,
    region VARCHAR,
    sales_amount DECIMAL(10,2),
    sales_quarter VARCHAR
);

INSERT INTO sales_performance VALUES
    ('Laptop', 'North', 50000.00, 'Q2'),
    ('Smartphone', 'South', 45000.00, 'Q2'),
    ('Tablet', 'East', 30000.00, 'Q2');
'''
)

# Analyze regional sales performance
result = conn.execute('''
SELECT
    region,
    SUM(sales_amount) as total_regional_sales,
    AVG(sales_amount) as avg_product_sales
FROM sales_performance
GROUP BY region
ORDER BY total_regional_sales DESC
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('North', Decimal('50000.00'), 50000.0), ('South', Decimal('45000.00'), 45000.0), ('East', Decimal('30000.00'), 30000.0)]

**Explanation**: This example demonstrates creating a sales performance tracking table with product, region, sales amount, and quarter. The SQL query performs regional sales analysis by calculating total and average sales per region, showcasing DuckDB's aggregation and grouping capabilities.
## Step 27: # Execute and display results

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('''
CREATE TABLE products (
    id INTEGER,
    name VARCHAR,
    price DECIMAL(10,2)
);

INSERT INTO products VALUES
    (1, 'Laptop', 1200.50),
    (2, 'Smartphone', 800.25),
    (3, 'Tablet', 500.00);
''')

result = conn.execute('''
SELECT name, price
FROM products
WHERE price > 600
ORDER BY price DESC
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Laptop', Decimal('1200.50')), ('Smartphone', Decimal('800.25'))]

**Explanation**: Demonstrates a basic DuckDB query filtering products above $600, sorted by descending price. Shows table creation, data insertion, and filtering with ORDER BY clause.
## Step 28: print(rel.execute().fetchall())

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('CREATE TABLE temps (city VARCHAR, temp INTEGER)')
conn.execute("INSERT INTO temps VALUES ('NYC', 85), ('LA', 92), ('Chicago', 78)")

rel = conn.table('temps').filter('temp > 80').order('temp')
print(rel.execute().fetchall())
```

**Result**: [('Laptop', Decimal('1200.50')), ('Smartphone', Decimal('800.25'))]

**Explanation**: Demonstrates creating an in-memory table, filtering rows where temperature exceeds 80, and ordering results using DuckDB's relational API with method chaining.
## Step 29: ```

**Generated by**: Anthropic

```python
import duckdb

# Create in-memory database
conn = duckdb.connect(':memory:')

# Create table with time series weather data
conn.execute('''
CREATE TABLE weather_metrics (
    city VARCHAR,
    recorded_at TIMESTAMP,
    temperature DECIMAL(5,2),
    humidity INTEGER
);

INSERT INTO weather_metrics VALUES
    ('New York', '2023-07-20 10:00:00', 82.5, 65),
    ('New York', '2023-07-20 11:00:00', 83.2, 62),
    ('Chicago', '2023-07-20 10:00:00', 75.8, 70);
''')

# Use window functions to compute temperature trends
result = conn.execute('''
SELECT
    city,
    recorded_at,
    temperature,
    AVG(temperature) OVER (PARTITION BY city ORDER BY recorded_at ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) as rolling_avg,
    temperature - LAG(temperature) OVER (PARTITION BY city ORDER BY recorded_at) as temp_change
FROM weather_metrics
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Chicago', datetime.datetime(2023, 7, 20, 10, 0), Decimal('75.80'), 75.8, None), ('New York', datetime.datetime(2023, 7, 20, 10, 0), Decimal('82.50'), 82.5, None), ('New York', datetime.datetime(2023, 7, 20, 11, 0), Decimal('83.20'), 82.85, Decimal('0.70'))]

**Explanation**: Demonstrates advanced time series analysis using DuckDB window functions to compute rolling averages and temperature changes across multiple cities.
## Step 30: This example demonstrates window functions in the DuckDB relational API by calculating cumulative sales per category and ranking products within each category.

**Generated by**: Anthropic

```python
import duckdb

conn = duckdb.connect(':memory:')

conn.execute('''
CREATE TABLE product_sales (
    category VARCHAR,
    product VARCHAR,
    sale_amount DECIMAL(10,2)
);

INSERT INTO product_sales VALUES
    ('Electronics', 'Laptop', 1200.50),
    ('Electronics', 'Smartphone', 800.25),
    ('Clothing', 'Jacket', 250.75);
''')

result = conn.execute('''
SELECT 
    category, 
    product, 
    sale_amount,
    SUM(sale_amount) OVER (PARTITION BY category ORDER BY sale_amount) as cumulative_category_sales,
    RANK() OVER (PARTITION BY category ORDER BY sale_amount DESC) as product_rank
FROM product_sales
ORDER BY category, product_rank
''').fetchall()

for row in result:
    print(row)
```

**Result**: [('Clothing', 'Jacket', Decimal('250.75'), Decimal('250.75'), 1), ('Electronics', 'Laptop', Decimal('1200.50'), Decimal('2000.75'), 1), ('Electronics', 'Smartphone', Decimal('800.25'), Decimal('800.25'), 2)]

**Explanation**: Demonstrates window functions in DuckDB by calculating cumulative sales per category and ranking products within categories. Shows how to use OVER, PARTITION BY, and ORDER BY clauses to perform advanced analytical queries.
